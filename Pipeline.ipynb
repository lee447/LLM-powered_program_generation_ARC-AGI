{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline: LLM-powered program generation for solving ARC-AGI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ollama\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared system prompt for all tasks\n",
    "system_prompt = \"\"\"\n",
    "You are a visual reasoning and Python programming expert solving ARC-AGI (Abstraction and Reasoning Corpus - Artificial General Intelligence) tasks.\n",
    "\n",
    "Each integer in the grid represents a color:\n",
    "0 = black, 1 = blue, 2 = red, 3 = green, 4 = yellow,\n",
    "5 = grey, 6 = pink, 7 = orange, 8 = light blue, 9 = brown.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = \"\"\"\n",
    "Write a Python function that correctly transforms each input grid into its corresponding output grid based on the given examples.\n",
    "\n",
    "- The function must be named: `solve(grid: List[List[int]]) -> List[List[int]]`\n",
    "- Include only the code and necessary imports (e.g., `import numpy as np`)\n",
    "- Do not include comments, explanations, or print statements\n",
    "- Do not hard-code values or specific grid sizes — the function must generalize based on the patterns in the examples\n",
    "- Ensure your solution works for all provided input-output pairs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Write a Python function that correctly transforms each input grid into its corresponding output grid based on the given examples.\n",
      "\n",
      "- The function must be named: `solve(grid: List[List[int]]) -> List[List[int]]`\n",
      "- Include only the code and necessary imports (e.g., `import numpy as np`)\n",
      "- Do not include comments, explanations, or print statements\n",
      "- Do not hard-code values or specific grid sizes — the function must generalize based on the patterns in the examples\n",
      "- Ensure your solution works for all provided input-output pairs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(base_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = \"\"\"\n",
    "List visual observations from the training pairs.\n",
    "\n",
    "- Use bullet points (max 10).\n",
    "- Focus on colors, shapes, object counts, positions, and differences.\n",
    "- Avoid reasoning or explanations.\n",
    "- Be concise. No full sentences, no extra formatting.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List visual observations from the training pairs.\n",
      "\n",
      "- Use bullet points (max 10).\n",
      "- Focus on colors, shapes, object counts, positions, and differences.\n",
      "- Avoid reasoning or explanations.\n",
      "- Be concise. No full sentences, no extra formatting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = \"\"\"\n",
    "Describe the transformation(s) from input to output grids.\n",
    "\n",
    "- Use 3 to 5 short sentences.\n",
    "- Focus on what changes: movement, color, shape, duplication, etc.\n",
    "- Mention if the transformation is based on position, context, or rules.\n",
    "- Avoid implementation hints or code.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Describe the transformation(s) from input to output grids.\n",
      "\n",
      "- Use 3 to 5 short sentences.\n",
      "- Focus on what changes: movement, color, shape, duplication, etc.\n",
      "- Mention if the transformation is based on position, context, or rules.\n",
      "- Avoid implementation hints or code.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3 = \"\"\"\n",
    "Reflect on how you would solve the task in Python.\n",
    "\n",
    "- Use 3 to 5 sentences.\n",
    "- Mention your overall approach, logical steps, and possible uncertainties.\n",
    "- Do not return code or pseudocode.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reflect on how you would solve the task in Python.\n",
      "\n",
      "- Use 3 to 5 sentences.\n",
      "- Mention your overall approach, logical steps, and possible uncertainties.\n",
      "- Do not return code or pseudocode.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add outputs of secondary prompts to other secondary prompts (especially for prompt 3) Maybe \"buildPrompt\" function.\n",
    "#TODO: Create Revision prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_4 = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tasks(folder):\n",
    "    tasks = []\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        if filename.endswith(\".json\"):\n",
    "            with open(os.path.join(folder, filename), \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                tasks.append({\"filename\": filename, \"data\": data})\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load API-Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_api_key(file_path=\"key.env\"):\n",
    "    load_dotenv(file_path)\n",
    "    import openai\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai.api_key:\n",
    "        print(\"No API key found. Please set OPENAI_API_KEY in key.env.\")\n",
    "    global client\n",
    "    client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"o3-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and Combining Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds the tasks demonstration pairs to the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tasks(prompt, task_data):\n",
    "    full_prompt = prompt.strip() + \"\\n\\nHere are the demonstration pairs (JSON data):\\n\"\n",
    "    for i, pair in enumerate(task_data['train']):\n",
    "        full_prompt += f\"\\nTrain Input {i+1}: {pair['input']}\\n\"\n",
    "        full_prompt += f\"Train Output {i+1}: {pair['output']}\\n\"\n",
    "    return full_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines secondary prompt 1 and 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prompts_1_and_2(prompt_1_response, prompt_2_template):\n",
    "    combined_prompt = f\"\"\"{prompt_2_template.strip()}\n",
    "\n",
    "Here are visual observations of the task at hand, that may assist you in identifying the transformation:\n",
    "\n",
    "{prompt_1_response.strip()}\n",
    "\n",
    "Now provide your transformation analysis based on these observations.\"\"\"\n",
    "    return combined_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines secondary prompt 1, 2 and 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prompts_1_2_and_3(prompt_1_response, prompt_2_response, prompt_3_template):\n",
    "    combined_prompt = f\"\"\"{prompt_3_template.strip()}\n",
    "\n",
    "Here are visual observations of the task that may help inform your implementation:\n",
    "{prompt_1_response.strip()}\n",
    "\n",
    "Here are the transformation rules that have been identified based on the task:\n",
    "{prompt_2_response.strip()}\n",
    "\n",
    "Now reflect on how you would implement a solution to this task in Python, following the instructions above.\n",
    "\"\"\"\n",
    "    return combined_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines secondary prompt 3 with the base prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prompts_3_and_base(prompt_3_response, prompt_base_template):\n",
    "    combined_prompt = f\"\"\"\n",
    "Implementation Reflection:\n",
    "{prompt_3_response.strip()}\n",
    "\n",
    "{prompt_base_template.strip()}\n",
    "\"\"\"\n",
    "    return combined_prompt.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine responses of the secondary prompt to the base prompt to create task-tailored prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompts(task_data):\n",
    "    # Build secondary prompt 1\n",
    "    full_prompt_1 = add_tasks(prompt_1, task_data)\n",
    "    response_1 = call_gpt(full_prompt_1)\n",
    "    print('Built prompt 1')\n",
    "    \n",
    "    # Build secondary prompt 2\n",
    "    combined_prompt_2 = combine_prompts_1_and_2(response_1, prompt_2)\n",
    "    full_prompt_2 = add_tasks(combined_prompt_2, task_data)\n",
    "    response_2 = call_gpt(full_prompt_2)\n",
    "    print('Built prompt 2')\n",
    "    \n",
    "    # Build secondary prompt 3\n",
    "    combined_prompt_3 = combine_prompts_1_2_and_3(response_1, response_2, prompt_3)\n",
    "    full_prompt_3 = add_tasks(combined_prompt_3, task_data)\n",
    "    response_3 = call_gpt(full_prompt_3)\n",
    "    print('Built prompt 3')\n",
    "    \n",
    "    # Build task-tailored prompt\n",
    "    combined_prompt_base = combine_prompts_3_and_base(response_3, base_prompt)\n",
    "    tailored_prompt = add_tasks(combined_prompt_base, task_data)\n",
    "    \n",
    "    return tailored_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_program(program_text, task_id):\n",
    "    import re\n",
    "\n",
    "    # Define the base and task-specific folder paths\n",
    "    base_folder = \"Candidate_programs\"\n",
    "    task_folder = os.path.join(base_folder, f\"task_{task_id}\")\n",
    "    \n",
    "    # Create the task-specific folder if it doesn't exist\n",
    "    os.makedirs(task_folder, exist_ok=True)\n",
    "\n",
    "    # Remove ```python or ``` if present\n",
    "    cleaned_text = re.sub(r\"^```(?:python)?\\s*|```$\", \"\", program_text.strip(), flags=re.MULTILINE)\n",
    "\n",
    "    # Find the next available version number\n",
    "    existing_files = os.listdir(task_folder)\n",
    "    version_numbers = [\n",
    "        int(re.search(r\"solution_v(\\d+)\\.py\", fname).group(1))\n",
    "        for fname in existing_files\n",
    "        if re.match(r\"solution_v\\d+\\.py\", fname)\n",
    "    ]\n",
    "    next_version = max(version_numbers, default=0) + 1\n",
    "    \n",
    "    # Define the full path to the new Python file\n",
    "    file_path = os.path.join(task_folder, f\"solution_v{next_version}.py\")\n",
    "    \n",
    "    # Save the program text to the file\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(cleaned_text.strip())\n",
    "\n",
    "    \n",
    "    print(f\"Saved program for task {task_id} as version {next_version}: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_programs(tailored_prompt, task_index):\n",
    "    # Create two programs\n",
    "    for i in range(2):\n",
    "        # Call the model with the tailored prompt\n",
    "        response = call_gpt(tailored_prompt)\n",
    "        \n",
    "        # Save the generated program\n",
    "        save_program(response, task_index)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built prompt 1\n",
      "Built prompt 2\n",
      "Built prompt 3\n",
      "Saved program for task 0 as version 1: Candidate_programs\\task_0\\solution_v1.py\n",
      "Saved program for task 0 as version 2: Candidate_programs\\task_0\\solution_v2.py\n"
     ]
    }
   ],
   "source": [
    "tasks = load_tasks(\"evaluation_set\")\n",
    "load_api_key()\n",
    "\n",
    "for i, task in enumerate(tasks[:1]):\n",
    "    # Build secondary prompts and create tailored_prompt from their responses\n",
    "    tailored_prompt = build_prompts(task['data'])\n",
    "    # Create two programs based on the tailored prompt\n",
    "    create_programs(tailored_prompt, i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implementation Reflection:\n",
      "I would use a flood-fill or connected-components algorithm to scan the grid and group pixels by color into connected regions. Then I would compute the bounding boxes for the significant clusters, filtering out those that are too small or peripheral, and fill in each valid region uniformly with its dominant color. I would then reassemble the grid by replacing the clusters with these solid blocks while leaving the background unchanged. One possible uncertainty is tuning the thresholds that determine when a cluster is considered stray or peripheral versus part of a central, valid shape.\n",
      "\n",
      "Write a Python function that correctly transforms each input grid into its corresponding output grid based on the given examples.\n",
      "\n",
      "- The function must be named: `solve(grid: List[List[int]]) -> List[List[int]]`\n",
      "- Include only the code and necessary imports (e.g., `import numpy as np`)\n",
      "- Do not include comments, explanations, or print statements\n",
      "- Do not hard-code values or specific grid sizes — the function must generalize based on the patterns in the examples\n",
      "- Ensure your solution works for all provided input-output pairs\n",
      "\n",
      "Here are the demonstration pairs (JSON data):\n",
      "\n",
      "Train Input 1: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0], [0, 0, 6, 6, 6, 6, 6, 6, 0, 0, 6, 6, 6, 6, 3, 6, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 8, 3, 3, 3, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 3, 0, 0, 0], [0, 3, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 3, 0, 0, 0, 3, 0, 0], [0, 3, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 3, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 6, 6, 6, 6, 6, 6, 0, 0, 6, 6, 3, 6, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 3, 8, 3, 3, 8, 3, 0, 3, 0, 0, 0, 3], [0, 0, 8, 8, 3, 3, 3, 8, 0, 0, 3, 8, 3, 3, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 8, 3, 3, 3, 3, 8, 0, 0, 0, 0, 0, 0], [3, 3, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 6, 6, 3, 6, 6, 6, 0, 3, 6, 6, 6, 3, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 0, 0, 3, 0], [0, 0, 8, 3, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Train Output 1: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 6, 6, 6, 6, 6, 6, 0, 0, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 6, 6, 6, 6, 6, 6, 0, 0, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 6, 6, 6, 6, 6, 6, 0, 0, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 8, 8, 3, 3, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "\n",
      "Train Input 2: [[0, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 1, 1, 1, 2, 3, 3, 0, 3, 0, 0], [0, 1, 1, 3, 3, 3, 0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 3, 0, 3, 0], [0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 1, 1, 1, 3, 3, 0, 0, 0, 3], [0, 1, 3, 3, 3, 1, 0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 0, 0, 0], [0, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 3, 1, 3, 3, 3, 0, 3, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 0, 3, 0], [0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 0, 0, 0], [0, 1, 1, 2, 3, 3, 0, 1, 3, 2, 1, 3, 0, 1, 1, 2, 3, 3, 0, 0, 0, 0], [1, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 3, 1, 3, 2, 3, 3, 0, 0, 0, 0], [0, 8, 1, 8, 8, 3, 0, 8, 8, 8, 8, 8, 0, 1, 8, 8, 8, 8, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 0], [0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 0, 3, 0], [0, 1, 1, 3, 3, 3, 0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 0, 0, 0], [0, 1, 1, 2, 3, 3, 0, 1, 1, 1, 3, 3, 0, 1, 1, 2, 3, 1, 0, 0, 0, 0], [1, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 1, 0, 1, 1, 2, 3, 3, 0, 0, 0, 0], [3, 8, 8, 8, 3, 3, 1, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 0, 0, 1, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 3, 3, 0, 3, 0, 3, 0, 1, 1, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Train Output 2: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 0, 0, 0], [0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 0, 0, 0], [0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 0, 0, 0], [0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 0, 0, 0], [0, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 0, 0, 0], [0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 0, 0, 0], [0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 0, 0, 0], [0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 0, 0, 0], [0, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 0, 0, 0], [0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 0, 0, 0], [0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 0, 0, 0], [0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 1, 1, 2, 3, 3, 0, 0, 0, 0], [0, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "\n",
      "Train Input 3: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3], [0, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 3], [0, 3, 2, 2, 3, 0, 0, 3, 2, 2, 3, 0, 3, 3, 2, 2, 3, 0, 0, 3, 0, 0], [0, 2, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0], [0, 2, 3, 1, 3, 0, 0, 2, 2, 1, 2, 0, 0, 3, 1, 1, 3, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0], [0, 2, 2, 2, 2, 3, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0], [0, 3, 2, 2, 3, 0, 0, 3, 2, 2, 3, 0, 3, 3, 2, 2, 3, 2, 0, 0, 0, 0], [0, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0], [0, 3, 3, 1, 3, 0, 0, 3, 1, 1, 3, 0, 0, 3, 1, 1, 3, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 2, 2, 0, 0, 3, 2, 3, 2, 0, 0, 2, 3, 2, 2, 0, 0, 0, 0, 0], [0, 3, 2, 2, 3, 0, 0, 3, 2, 3, 3, 0, 0, 3, 2, 3, 3, 0, 0, 0, 0, 0], [3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 3, 2, 3, 3, 0, 0, 2, 0, 0], [0, 3, 1, 1, 3, 0, 3, 3, 1, 1, 3, 0, 0, 3, 1, 1, 3, 0, 0, 0, 0, 0], [0, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 3, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 0, 0, 0, 0, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0], [0, 0, 0, 3, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Train Output 3: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0], [0, 3, 2, 2, 3, 0, 0, 3, 2, 2, 3, 0, 0, 3, 2, 2, 3, 0, 0, 0, 0, 0], [0, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0], [0, 3, 1, 1, 3, 0, 0, 3, 1, 1, 3, 0, 0, 3, 1, 1, 3, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0], [0, 3, 2, 2, 3, 0, 0, 3, 2, 2, 3, 0, 0, 3, 2, 2, 3, 0, 0, 0, 0, 0], [0, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0], [0, 3, 1, 1, 3, 0, 0, 3, 1, 1, 3, 0, 0, 3, 1, 1, 3, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0], [0, 3, 2, 2, 3, 0, 0, 3, 2, 2, 3, 0, 0, 3, 2, 2, 3, 0, 0, 0, 0, 0], [0, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 0, 0, 0, 0, 0], [0, 3, 1, 1, 3, 0, 0, 3, 1, 1, 3, 0, 0, 3, 1, 1, 3, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tailored_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
