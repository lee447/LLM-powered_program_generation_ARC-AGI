{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline: LLM-powered program generation for solving ARC-AGI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ollama\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared system prompt for all tasks\n",
    "system_prompt = \"\"\"\n",
    "You are a visual reasoning and Python programming expert solving ARC-AGI (Abstraction and Reasoning Corpus - Artificial General Intelligence) tasks.\n",
    "\n",
    "Each integer in the grid represents a color:\n",
    "0 = black, 1 = blue, 2 = red, 3 = green, 4 = yellow,\n",
    "5 = grey, 6 = pink, 7 = orange, 8 = light blue, 9 = brown.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = \"\"\"\n",
    "Write a Python function that correctly transforms each input grid into its corresponding output grid based on the given examples.\n",
    "\n",
    "- The function must be named: `solve(grid: List[List[int]]) -> List[List[int]]`\n",
    "- Include only the code and necessary imports (e.g., `import numpy as np`)\n",
    "- Do not include comments, explanations, or print statements\n",
    "- Do not hard-code values or specific grid sizes — the function must generalize based on the patterns in the examples\n",
    "- Ensure your solution works for all provided input-output pairs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Write a Python function that correctly transforms each input grid into its corresponding output grid based on the given examples.\n",
      "\n",
      "- The function must be named: `solve(grid: List[List[int]]) -> List[List[int]]`\n",
      "- Include only the code and necessary imports (e.g., `import numpy as np`)\n",
      "- Do not include comments, explanations, or print statements\n",
      "- Do not hard-code values or specific grid sizes — the function must generalize based on the patterns in the examples\n",
      "- Ensure your solution works for all provided input-output pairs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(base_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = \"\"\"\n",
    "List visual observations from the training pairs.\n",
    "\n",
    "- Use bullet points (max 10).\n",
    "- Focus on colors, shapes, object counts, positions, and differences.\n",
    "- Avoid reasoning or explanations.\n",
    "- Be concise. No full sentences, no extra formatting.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List visual observations from the training pairs.\n",
      "\n",
      "- Use bullet points (max 10).\n",
      "- Focus on colors, shapes, object counts, positions, and differences.\n",
      "- Avoid reasoning or explanations.\n",
      "- Be concise. No full sentences, no extra formatting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = \"\"\"\n",
    "Describe the transformation(s) from input to output grids.\n",
    "\n",
    "- Use 3 to 5 short sentences.\n",
    "- Focus on what changes: movement, color, shape, duplication, etc.\n",
    "- Mention if the transformation is based on position, context, or rules.\n",
    "- Avoid implementation hints or code.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Describe the transformation(s) from input to output grids.\n",
      "\n",
      "- Use 3 to 5 short sentences.\n",
      "- Focus on what changes: movement, color, shape, duplication, etc.\n",
      "- Mention if the transformation is based on position, context, or rules.\n",
      "- Avoid implementation hints or code.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3 = \"\"\"\n",
    "Reflect on how you would solve the task in Python.\n",
    "\n",
    "- Use 3 to 5 sentences.\n",
    "- Mention your overall approach, logical steps, and possible uncertainties.\n",
    "- Do not return code or pseudocode.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reflect on how you would solve the task in Python.\n",
      "\n",
      "- Use 3 to 5 sentences.\n",
      "- Mention your overall approach, logical steps, and possible uncertainties.\n",
      "- Do not return code or pseudocode.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add outputs of secondary prompts to other secondary prompts (especially for prompt 3) Maybe \"buildPrompt\" function.\n",
    "#TODO: Create Revision prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_4 = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tasks(folder):\n",
    "    tasks = []\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        if filename.endswith(\".json\"):\n",
    "            with open(os.path.join(folder, filename), \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                tasks.append({\"filename\": filename, \"data\": data})\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load API-Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_api_key(file_path=\"key.env\"):\n",
    "    load_dotenv(file_path)\n",
    "    import openai\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai.api_key:\n",
    "        print(\"No API key found. Please set OPENAI_API_KEY in key.env.\")\n",
    "    global client\n",
    "    client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and Combining Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds the tasks demonstration pairs to the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(prompt, task_data):\n",
    "    full_prompt = prompt.strip() + \"\\n\\nHere are the demonstration pairs (JSON data):\\n\"\n",
    "    for i, pair in enumerate(task_data['train']):\n",
    "        full_prompt += f\"\\nTrain Input {i+1}: {pair['input']}\\n\"\n",
    "        full_prompt += f\"Train Output {i+1}: {pair['output']}\\n\"\n",
    "    return full_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines secondary prompt 1 and 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prompts_1_and_2(prompt_1_response, prompt_2_template):\n",
    "    combined_prompt = f\"\"\"{prompt_2_template.strip()}\n",
    "\n",
    "Here are visual observations of the task at hand, that may assist you in identifying the transformation:\n",
    "\n",
    "{prompt_1_response.strip()}\n",
    "\n",
    "Now provide your transformation analysis based on these observations.\"\"\"\n",
    "    return combined_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines secondary prompt 1, 2 and 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prompts_1_2_and_3(prompt_1_response, prompt_2_response, prompt_3_template):\n",
    "    combined_prompt = f\"\"\"{prompt_3_template.strip()}\n",
    "\n",
    "Here are visual observations of the task that may help inform your implementation:\n",
    "{prompt_1_response.strip()}\n",
    "\n",
    "Here are the transformation rules that have been identified based on the task:\n",
    "{prompt_2_response.strip()}\n",
    "\n",
    "Now reflect on how you would implement a solution to this task in Python, following the instructions above.\n",
    "\"\"\"\n",
    "    return combined_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines secondary prompt 3 with the base prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prompts_3_and_base(prompt_3_response, prompt_base_template):\n",
    "    combined_prompt = f\"\"\"\n",
    "Implementation Reflection:\n",
    "{prompt_3_response.strip()}\n",
    "\n",
    "{prompt_base_template.strip()}\n",
    "\"\"\"\n",
    "    return combined_prompt.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_program(program_text, task_id):\n",
    "    import re\n",
    "\n",
    "    # Define the base and task-specific folder paths\n",
    "    base_folder = \"Candidate_programs\"\n",
    "    task_folder = os.path.join(base_folder, f\"task_{task_id}\")\n",
    "    \n",
    "    # Create the task-specific folder if it doesn't exist\n",
    "    os.makedirs(task_folder, exist_ok=True)\n",
    "\n",
    "    # Remove ```python or ``` if present\n",
    "    cleaned_text = re.sub(r\"^```(?:python)?\\s*|```$\", \"\", program_text.strip(), flags=re.MULTILINE)\n",
    "\n",
    "    # Find the next available version number\n",
    "    existing_files = os.listdir(task_folder)\n",
    "    version_numbers = [\n",
    "        int(re.search(r\"solution_v(\\d+)\\.py\", fname).group(1))\n",
    "        for fname in existing_files\n",
    "        if re.match(r\"solution_v\\d+\\.py\", fname)\n",
    "    ]\n",
    "    next_version = max(version_numbers, default=0) + 1\n",
    "    \n",
    "    # Define the full path to the new Python file\n",
    "    file_path = os.path.join(task_folder, f\"solution_v{next_version}.py\")\n",
    "    \n",
    "    # Save the program text to the file\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(cleaned_text.strip())\n",
    "\n",
    "    \n",
    "    print(f\"✅ Saved program for task {task_id} as version {next_version}: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"o3-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt 1 Response for task 83:\n",
      "- Predominantly blank backgrounds (color 0) in all grids.\n",
      "- Central patterns formed by nonzero colors (2, 1, 5) in inputs.\n",
      "- Train 1: Color 2 arranged in a rectangular/square pattern.\n",
      "- Train 2: Color 1 arranged in an uneven, connected pattern.\n",
      "- Train 3: Color 5 arranged in a blocky, repeated pattern.\n",
      "- Outputs add a continuous line of color 3 (green) across one row in Train 1 and 2.\n",
      "- Output 3 shows a vertical stripe of color 3 (green) replacing part of the structure.\n",
      "- Underlying object shapes remain while a green line is superimposed.\n",
      "\n",
      "Prompt 2 Response for task 83:\n",
      "In each case the base pattern is preserved, but a new continuous green (color 3) line is added. In the first two examples, a horizontal green stripe is inserted along the fifth row of the grid, overriding any existing values in that row. In the third example, a vertical green stripe is drawn down the center column instead. The transformation is positional, replacing an entire row or column with green irrespective of the original pattern in that area.\n",
      "\n",
      "Prompt 3 Response for task 83:\n",
      "I would analyze the input grid dimensions and then check if the green line should be horizontal or vertical based on the structure of the non-zero pattern. For the horizontal case, I’d override the entire fifth row of the grid with green (color 3), while for the vertical case I’d replace the cells in the center column with green, always preserving the original surrounding pattern. One uncertainty is determining the condition under which to choose a horizontal versus a vertical line, so I’d confirm this by comparing characteristics of the central pattern in the input grid before applying the transformation.\n",
      "\n",
      "Base Prompt Response for task 83:\n",
      "from typing import List\n",
      "def solve(grid: List[List[int]]) -> List[List[int]]:\n",
      "    h = len(grid)\n",
      "    w = len(grid[0]) if h else 0\n",
      "    bg = 0\n",
      "    rmin, rmax = h, -1\n",
      "    cmin, cmax = w, -1\n",
      "    for i in range(h):\n",
      "        for j in range(w):\n",
      "            if grid[i][j] != bg:\n",
      "                rmin = min(rmin, i)\n",
      "                rmax = max(rmax, i)\n",
      "                cmin = min(cmin, j)\n",
      "                cmax = max(cmax, j)\n",
      "    if rmax == -1:\n",
      "        return grid\n",
      "    candidate_h = (h - 1) // 2\n",
      "    candidate_v = (w - 1) // 2\n",
      "    use_horizontal = False\n",
      "    use_vertical = False\n",
      "    if rmin <= candidate_h <= rmax:\n",
      "        gap = True\n",
      "        for j in range(cmin, cmax + 1):\n",
      "            if grid[candidate_h][j] != bg:\n",
      "                gap = False\n",
      "                break\n",
      "        if gap:\n",
      "            use_horizontal = True\n",
      "    if not use_horizontal and cmin <= candidate_v <= cmax:\n",
      "        gap = True\n",
      "        for i in range(rmin, rmax + 1):\n",
      "            if grid[i][candidate_v] != bg:\n",
      "                gap = False\n",
      "                break\n",
      "        if gap:\n",
      "            use_vertical = True\n",
      "    if use_horizontal:\n",
      "        for j in range(w):\n",
      "            grid[candidate_h][j] = 3\n",
      "    elif use_vertical:\n",
      "        for i in range(h):\n",
      "            grid[i][candidate_v] = 3\n",
      "    return grid\n",
      "\n",
      "✅ Saved program for task 83 as version 1: Candidate_programs\\task_83\\solution_v1.py\n"
     ]
    }
   ],
   "source": [
    "tasks = load_tasks(\"evaluation_set\")\n",
    "load_api_key()\n",
    "\n",
    "# Find task with filename \"817e6c09.json\"\n",
    "target_filename = \"da2b0fe3.json\"\n",
    "task = next(t for t in tasks if t[\"filename\"] == target_filename)\n",
    "\n",
    "# Use task directly (no loop needed if it's just one)\n",
    "task_id = tasks.index(task) + 1  # Optional: preserve position info\n",
    "\n",
    "# Build and run secondary prompts:\n",
    "full_prompt_1 = build_prompt(prompt_1, task[\"data\"])\n",
    "response_1 = call_gpt(full_prompt_1)\n",
    "print(f\"Prompt 1 Response for task {task_id}:\\n{response_1}\\n\")\n",
    "\n",
    "combined_prompt_2 = combine_prompts_1_and_2(response_1, prompt_2)\n",
    "full_prompt_2 = build_prompt(combined_prompt_2, task[\"data\"])\n",
    "response_2 = call_gpt(full_prompt_2)\n",
    "print(f\"Prompt 2 Response for task {task_id}:\\n{response_2}\\n\")\n",
    "\n",
    "combined_prompt_3 = combine_prompts_1_2_and_3(response_1, response_2, prompt_3)\n",
    "full_prompt_3 = build_prompt(combined_prompt_3, task[\"data\"])\n",
    "response_3 = call_gpt(full_prompt_3)\n",
    "print(f\"Prompt 3 Response for task {task_id}:\\n{response_3}\\n\")\n",
    "\n",
    "combined_prompt_base = combine_prompts_3_and_base(response_3, base_prompt)\n",
    "tailored_prompt = build_prompt(combined_prompt_base, task[\"data\"])\n",
    "response = call_gpt(tailored_prompt)\n",
    "print(f\"Base Prompt Response for task {task_id}:\\n{response}\\n\")\n",
    "\n",
    "save_program(response, task_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a Python function that correctly transforms each input grid into its corresponding output grid based on the given examples.\n",
      "\n",
      "- The function must be named: `solve(grid: List[List[int]]) -> List[List[int]]`\n",
      "- Include only the code and necessary imports (e.g., `import numpy as np`)\n",
      "- Do not include comments, explanations, or print statements\n",
      "- Do not hard-code values or specific grid sizes — the function must generalize based on the patterns in the examples\n",
      "- Ensure your solution works for all provided input-output pairs\n",
      "\n",
      "Here are the demonstration pairs (JSON data):\n",
      "\n",
      "Train Input 1: [[2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0], [2, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0], [0, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0], [0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0], [0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2], [0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2]]\n",
      "Train Output 1: [[8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0], [8, 8, 0, 0, 8, 8, 0, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0], [0, 0, 0, 0, 8, 8, 0, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0], [0, 2, 2, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0, 2, 2, 0, 0], [0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0], [0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 0, 8, 8], [0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 8, 8]]\n",
      "\n",
      "Train Input 2: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2], [0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2], [0, 2, 2, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0], [0, 0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Train Output 2: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 8], [0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 8, 8], [0, 2, 2, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0], [0, 0, 0, 8, 8, 0, 0, 8, 8, 0, 0, 0, 0, 0], [0, 0, 0, 8, 8, 0, 0, 8, 8, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "\n",
      "Train Input 3: [[0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 2, 2], [0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2], [0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0], [2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0], [2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0]]\n",
      "Train Output 3: [[0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 8, 8], [0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 8], [0, 0, 2, 2, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 8, 8, 0, 8, 8, 0, 0, 0, 0, 0], [8, 8, 0, 0, 0, 8, 8, 0, 0, 0, 0, 2, 2, 0, 0], [8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0]]\n",
      "\n",
      "Train Input 4: [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 2, 2], [2, 2, 0, 0, 0, 2, 2], [2, 2, 0, 0, 0, 0, 0], [0, 0, 2, 2, 0, 0, 0], [0, 0, 2, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0]]\n",
      "Train Output 4: [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 8, 8], [8, 8, 0, 0, 0, 8, 8], [8, 8, 0, 0, 0, 0, 0], [0, 0, 2, 2, 0, 0, 0], [0, 0, 2, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0]]\n",
      "\n",
      "Train Input 5: [[0, 0, 0, 0, 0], [2, 2, 0, 0, 0], [2, 2, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 2, 2], [0, 0, 0, 2, 2], [0, 0, 0, 0, 0]]\n",
      "Train Output 5: [[0, 0, 0, 0, 0], [2, 2, 0, 0, 0], [2, 2, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 8, 8], [0, 0, 0, 8, 8], [0, 0, 0, 0, 0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tailored_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
