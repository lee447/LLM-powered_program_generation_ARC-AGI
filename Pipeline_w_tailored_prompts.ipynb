{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline: LLM-powered program generation for solving ARC-AGI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ollama\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import ast\n",
    "import re\n",
    "import importlib.util\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared system prompt for all tasks\n",
    "system_prompt = \"\"\"\n",
    "You are a visual reasoning and Python programming expert solving ARC-AGI (Abstraction and Reasoning Corpus - Artificial General Intelligence) tasks.\n",
    "\n",
    "Each integer in the grid represents a color:\n",
    "0 = black, 1 = blue, 2 = red, 3 = green, 4 = yellow,\n",
    "5 = grey, 6 = pink, 7 = orange, 8 = light blue, 9 = brown.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = \"\"\"\n",
    "Write a Python function that correctly transforms each input grid into its corresponding output grid based on the given examples.\n",
    "\n",
    "- ONLY return code. No explanations or anything other than code.\n",
    "- The function must be named: `solve(grid: List[List[int]]) -> List[List[int]]`\n",
    "- Use only pure Python — do not import or use libraries like NumPy\n",
    "- Do not include comments, explanations, or print statements\n",
    "- Do not hard-code values or specific grid sizes — the function must generalize based on the patterns in the examples\n",
    "- The function must return a plain 2D list of integers with consistent row lengths (List[List[int]])\n",
    "- Do not return arrays, nested arrays, floats, or 3D structures\n",
    "- Ensure your solution works for all provided input-output pairs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Write a Python function that correctly transforms each input grid into its corresponding output grid based on the given examples.\n",
      "\n",
      "- ONLY return code. No explanations or anything other than code.\n",
      "- The function must be named: `solve(grid: List[List[int]]) -> List[List[int]]`\n",
      "- Use only pure Python — do not import or use libraries like NumPy\n",
      "- Do not include comments, explanations, or print statements\n",
      "- Do not hard-code values or specific grid sizes — the function must generalize based on the patterns in the examples\n",
      "- The function must return a plain 2D list of integers with consistent row lengths (List[List[int]])\n",
      "- Do not return arrays, nested arrays, floats, or 3D structures\n",
      "- Ensure your solution works for all provided input-output pairs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(base_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = \"\"\"\n",
    "List visual observations from the training pairs.\n",
    "\n",
    "- Use bullet points (max 10).\n",
    "- Focus on colors, shapes, object counts, positions, and fixed elements (e.g., anchors, borders, gray blocks).\n",
    "- Mention groupings or repeated patterns if visible.\n",
    "- Avoid reasoning or explanations.\n",
    "- Be concise. No full sentences, no extra formatting.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List visual observations from the training pairs.\n",
      "\n",
      "- Use bullet points (max 10).\n",
      "- Focus on colors, shapes, object counts, positions, and fixed elements (e.g., anchors, borders, gray blocks).\n",
      "- Mention groupings or repeated patterns if visible.\n",
      "- Avoid reasoning or explanations.\n",
      "- Be concise. No full sentences, no extra formatting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = \"\"\"\n",
    "Describe the transformation(s) from input to output grids.\n",
    "\n",
    "- Use 3 to 5 short sentences.\n",
    "- Focus on what changes: movement, color, shape, duplication, stacking, mirroring, etc.\n",
    "- Mention any use of anchors, fixed positions, or reference structures.\n",
    "- If applicable, describe how objects are grouped, reassigned, or reorganized.\n",
    "- Avoid implementation hints or code.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Describe the transformation(s) from input to output grids.\n",
      "\n",
      "- Use 3 to 5 short sentences.\n",
      "- Focus on what changes: movement, color, shape, duplication, stacking, mirroring, etc.\n",
      "- Mention any use of anchors, fixed positions, or reference structures.\n",
      "- If applicable, describe how objects are grouped, reassigned, or reorganized.\n",
      "- Avoid implementation hints or code.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3 = \"\"\"\n",
    "Reflect on how you would solve the task in Python.\n",
    "\n",
    "- Use 3 to 5 sentences.\n",
    "- Describe the main approach, such as identifying anchors, grouping objects, and applying transformations.\n",
    "- Mention steps like scanning for fixed elements, sorting, or aligning data.\n",
    "- Call out any challenges or unclear rules you would need to test for.\n",
    "- Do not return code or pseudocode.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reflect on how you would solve the task in Python.\n",
      "\n",
      "- Use 3 to 5 sentences.\n",
      "- Describe the main approach, such as identifying anchors, grouping objects, and applying transformations.\n",
      "- Mention steps like scanning for fixed elements, sorting, or aligning data.\n",
      "- Call out any challenges or unclear rules you would need to test for.\n",
      "- Do not return code or pseudocode.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "revision_prompt = \"\"\"\n",
    "In the following you'll receive a Python function that attempted to solve the following task. It did'nt succeed and you are tasked with fixing it.\n",
    "\n",
    "- The function must be named: `solve(grid: List[List[int]]) -> List[List[int]]`\n",
    "- Include only the code and necessary imports (e.g., `import numpy as np`)\n",
    "- Do not include comments, explanations, or print statements\n",
    "- Do not hard-code values or specific grid sizes — the function must generalize based on the patterns in the examples\n",
    "- Ensure your solution works for all provided input-output pairs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In the following you'll receive a Python function that attempted to solve the following task. It did'nt succeed and you are tasked with fixing it.\n",
      "\n",
      "- The function must be named: `solve(grid: List[List[int]]) -> List[List[int]]`\n",
      "- Include only the code and necessary imports (e.g., `import numpy as np`)\n",
      "- Do not include comments, explanations, or print statements\n",
      "- Do not hard-code values or specific grid sizes — the function must generalize based on the patterns in the examples\n",
      "- Ensure your solution works for all provided input-output pairs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(revision_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check manually entering one demonstration pair for each concept\n",
    "classification_prompt = \"\"\"\n",
    "You will receive a set of demonstration pairs (input and output grids) from a visual reasoning task.\n",
    "\n",
    "Your task is to classify the transformation into **one of the following 16 concepts**:\n",
    "\n",
    "- AboveBelow - Objects or patterns are arranged vertically, with relationships defined by what's above or below something else.\n",
    "- Center - Elements are moved to or arranged around the center of the grid.\n",
    "- CleanUp - The task removes noise or extraneous elements to leave a cleaner or more regular structure.\n",
    "- CompleteShape - A partial or broken shape is completed to form a full geometric object.\n",
    "- Copy - A shape or pattern is duplicated, often to another location in the grid.\n",
    "- Count - The number of certain elements is counted to determine placement, output quantity, or transformation.\n",
    "- ExtendToBoundary - Shapes or lines are extended until they touch the edge of the grid.\n",
    "- ExtractObjects - Specific objects are isolated and copied or transformed while others are ignored.\n",
    "- FilledNotFilled - The task distinguishes between filled and hollow shapes or fills in uncolored areas.\n",
    "- HorizontalVertical - Patterns follow or are transformed along horizontal or vertical axes, often involving symmetry or alignment.\n",
    "- InsideOutside - A relationship is determined based on whether elements are inside or outside a defined boundary.\n",
    "- MoveToBoundary - Objects are shifted to the nearest edge of the grid without rotation or change in shape.\n",
    "- Order - Items are rearranged according to size, color, frequency, or another ordinal property.\n",
    "- SameDifferent - Objects are retained or manipulated based on whether they match or differ in some attribute (e.g., color, shape).\n",
    "- TopBottom2D - A flat 2D interpretation of objects where the top and bottom halves of the grid are compared or modified.\n",
    "- TopBottom3D - The task simulates a 3D stacking or layering behavior, such as viewing objects from above or combining vertical slices.\n",
    "\n",
    "Instructions:\n",
    "- Respond ONLY with the exact name of the matching concept from the list above.\n",
    "- Do not explain your answer, just return the concept.\n",
    "- If uncertain, choose the concept that fits best based on the input-output transformations.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_concept_examples(concept_name, base_path=\"ConceptARC_Data\"):\n",
    "    concept_path = os.path.join(base_path, concept_name, \"task.json\")\n",
    "    if not os.path.exists(concept_path):\n",
    "        print(f\"[Warning] No concept task found for '{concept_name}'\")\n",
    "        return \"\"\n",
    "    \n",
    "    with open(concept_path, \"r\") as f:\n",
    "        concept_task = json.load(f)\n",
    "    \n",
    "    # Format the train pairs as in add_tasks\n",
    "    formatted_examples = \"\\n\\nHere are a few examples following the same concept that may help with solving this task. Keep in mind that the identified concept may be faulty:\\n\"\n",
    "    for i, pair in enumerate(concept_task.get(\"train\", [])):\n",
    "        formatted_examples += f\"\\nConcept Train Input {i+1}: {pair['input']}\\n\"\n",
    "        formatted_examples += f\"Concept Train Output {i+1}: {pair['output']}\\n\"\n",
    "    \n",
    "    return formatted_examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tasks(folder):\n",
    "    tasks = []\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        if filename.endswith(\".json\"):\n",
    "            with open(os.path.join(folder, filename), \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                tasks.append({\"filename\": filename, \"data\": data})\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load API-Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_api_key(file_path=\"key.env\"):\n",
    "    load_dotenv(file_path)\n",
    "    import openai\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai.api_key:\n",
    "        print(\"No API key found. Please set OPENAI_API_KEY in key.env.\")\n",
    "    global client\n",
    "    client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import openai\n",
    "\n",
    "def call_gpt(prompt, model=\"o4-mini\", retries=3):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                # Only for GPT-4o\n",
    "                # temperature=0.0\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        \n",
    "        except openai.RateLimitError as e:\n",
    "            wait_time = 5 + attempt * 5  # exponential backoff\n",
    "            print(f\"Rate limit hit. Waiting {wait_time} seconds before retrying...\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "    raise Exception(\"Rate limit retries exhausted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Non-zero Cords Encoding\n",
    "TODO: Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_nonzero_coordinates(grid):\n",
    "    coords = []\n",
    "    for i, row in enumerate(grid):\n",
    "        for j, val in enumerate(row):\n",
    "            if val != 0:\n",
    "                coords.append({\"row\": i, \"col\": j, \"val\": val})\n",
    "    return coords\n",
    "\n",
    "def encode_task_nonzero_coords(task):\n",
    "    encoded = {\"train\": [], \"test\": []}\n",
    "\n",
    "    for pair in task[\"train\"]:\n",
    "        encoded[\"train\"].append({\n",
    "            \"input\": encode_nonzero_coordinates(pair[\"input\"]),\n",
    "            \"output\": encode_nonzero_coordinates(pair[\"output\"])\n",
    "        })\n",
    "\n",
    "    for pair in task[\"test\"]:\n",
    "        encoded[\"test\"].append({\n",
    "            \"input\": encode_nonzero_coordinates(pair[\"input\"])\n",
    "        })\n",
    "\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Object/Bounding Box Encoding TODO: Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def extract_objects(grid):\n",
    "    visited = set()\n",
    "    objects = []\n",
    "    rows, cols = len(grid), len(grid[0])\n",
    "\n",
    "    def bfs(r, c, color):\n",
    "        q = deque([(r, c)])\n",
    "        visited.add((r, c))\n",
    "        pixels = [(r, c)]\n",
    "        min_r, min_c = r, c\n",
    "        max_r, max_c = r, c\n",
    "\n",
    "        while q:\n",
    "            cr, cc = q.popleft()\n",
    "            for dr, dc in [(-1,0), (1,0), (0,-1), (0,1)]:\n",
    "                nr, nc = cr + dr, cc + dc\n",
    "                if (\n",
    "                    0 <= nr < rows and\n",
    "                    0 <= nc < cols and\n",
    "                    (nr, nc) not in visited and\n",
    "                    grid[nr][nc] == color\n",
    "                ):\n",
    "                    visited.add((nr, nc))\n",
    "                    q.append((nr, nc))\n",
    "                    pixels.append((nr, nc))\n",
    "                    min_r = min(min_r, nr)\n",
    "                    min_c = min(min_c, nc)\n",
    "                    max_r = max(max_r, nr)\n",
    "                    max_c = max(max_c, nc)\n",
    "\n",
    "        return {\n",
    "            \"color\": color,\n",
    "            \"top_left\": [min_r, min_c],\n",
    "            \"width\": max_c - min_c + 1,\n",
    "            \"height\": max_r - min_r + 1,\n",
    "            \"pixels\": pixels\n",
    "        }\n",
    "\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            color = grid[r][c]\n",
    "            if color != 0 and (r, c) not in visited:\n",
    "                objects.append(bfs(r, c, color))\n",
    "\n",
    "    return objects\n",
    "\n",
    "def encode_task_objects(task):\n",
    "    encoded = {\"train\": [], \"test\": []}\n",
    "\n",
    "    for pair in task[\"train\"]:\n",
    "        encoded[\"train\"].append({\n",
    "            \"input\": extract_objects(pair[\"input\"]),\n",
    "            \"output\": extract_objects(pair[\"output\"])\n",
    "        })\n",
    "\n",
    "    for pair in task[\"test\"]:\n",
    "        encoded[\"test\"].append({\n",
    "            \"input\": extract_objects(pair[\"input\"])\n",
    "        })\n",
    "\n",
    "    return encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds Encodings to the Prompt with Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_encodings(prompt, encoding_dicts):\n",
    "    encoding_explanations = {\n",
    "        \"nonzero_coords\": \"This encoding lists only the non-zero cells as dictionaries containing their row, column, and value.\",\n",
    "        \"object_bbox\": \"This encoding represents each object in the grid as a group of connected same-colored cells, described by color, bounding box, and coordinates.\",\n",
    "    }\n",
    "\n",
    "    for encoding_name, encoding_data in encoding_dicts.items():\n",
    "        explanation = encoding_explanations.get(encoding_name, \"This encoding represents the input in an alternate form.\")\n",
    "        prompt += f\"\\n\\nEncoding used: {encoding_name}\\nExplanation: {explanation}\\n\\nHere are the demonstration pairs (encoded):\\n\"\n",
    "        for i, pair in enumerate(encoding_data[\"train\"]):\n",
    "            prompt += f\"\\nTrain Input {i+1}: {pair['input']}\\n\"\n",
    "            prompt += f\"Train Output {i+1}: {pair['output']}\\n\"\n",
    "    \n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building and Combining Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds the tasks demonstration pairs to the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tasks(prompt, task_data):\n",
    "    full_prompt = prompt.strip() + \"\\n\\nHere are the demonstration pairs (JSON data):\\n\"\n",
    "    for i, pair in enumerate(task_data['train']):\n",
    "        full_prompt += f\"\\nTrain Input {i+1}: {pair['input']}\\n\"\n",
    "        full_prompt += f\"Train Output {i+1}: {pair['output']}\\n\"\n",
    "    return full_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines secondary prompt 1 and 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prompts_1_and_2(prompt_1_response, prompt_2_template):\n",
    "    combined_prompt = f\"\"\"{prompt_2_template.strip()}\n",
    "\n",
    "Here are visual observations of the task at hand, that may assist you in identifying the transformation:\n",
    "\n",
    "{prompt_1_response.strip()}\n",
    "\n",
    "Now provide your transformation analysis based on these observations.\"\"\"\n",
    "    return combined_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines secondary prompt 1, 2 and 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prompts_1_2_and_3(prompt_1_response, prompt_2_response, prompt_3_template):\n",
    "    combined_prompt = f\"\"\"{prompt_3_template.strip()}\n",
    "\n",
    "Here are visual observations of the task that may help inform your implementation:\n",
    "{prompt_1_response.strip()}\n",
    "\n",
    "Here are the transformation rules that have been identified based on the task:\n",
    "{prompt_2_response.strip()}\n",
    "\n",
    "Now reflect on how you would implement a solution to this task in Python, following the instructions above.\n",
    "\"\"\"\n",
    "    return combined_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines secondary prompt 3 with the base prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prompts_and_base(prompt_1_response, prompt_2_response, prompt_3_response, prompt_base_template):\n",
    "    combined_prompt = f\"\"\"\n",
    "\n",
    "Here are visual observations of the task that may help inform your implementation:\n",
    "{prompt_1_response.strip()}\n",
    "\n",
    "Here are the transformation rules that have been identified based on the task:\n",
    "{prompt_2_response.strip()}\n",
    "    \n",
    "Here is a reflection on how you might implement a solution to this task in Python:\n",
    "{prompt_3_response.strip()}\n",
    "\n",
    "{prompt_base_template.strip()}\n",
    "\"\"\"\n",
    "    return combined_prompt.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine responses of the secondary prompt to the base prompt to create task-tailored prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global dictionary to store task concepts\n",
    "task_concepts = {}\n",
    "\n",
    "def build_prompts(task_data, task_id):\n",
    "    global task_concepts \n",
    "\n",
    "    encoding_dicts = {\n",
    "        \"nonzero_coords\": encode_task_nonzero_coords(task_data),\n",
    "    }\n",
    "\n",
    "    full_prompt_1 = add_tasks(prompt_1, task_data)\n",
    "    full_prompt_1 = add_encodings(full_prompt_1, encoding_dicts)\n",
    "    response_1 = call_gpt(full_prompt_1)\n",
    "\n",
    "    combined_prompt_2 = combine_prompts_1_and_2(response_1, prompt_2)\n",
    "    full_prompt_2 = add_tasks(combined_prompt_2, task_data)\n",
    "    full_prompt_2 = add_encodings(full_prompt_2, encoding_dicts)\n",
    "    response_2 = call_gpt(full_prompt_2)\n",
    "\n",
    "    combined_prompt_3 = combine_prompts_1_2_and_3(response_1, response_2, prompt_3)\n",
    "    full_prompt_3 = add_tasks(combined_prompt_3, task_data)\n",
    "    full_prompt_3 = add_encodings(full_prompt_3, encoding_dicts)\n",
    "    response_3 = call_gpt(full_prompt_3)\n",
    "\n",
    "    # Classification step\n",
    "    classification_full_prompt = add_tasks(classification_prompt, task_data)\n",
    "    classification_full_prompt = add_encodings(classification_full_prompt, encoding_dicts)\n",
    "    predicted_concept = call_gpt(classification_full_prompt).strip()\n",
    "    concept_instruction = load_concept_examples(predicted_concept)\n",
    "    task_concepts[task_id] = predicted_concept\n",
    "\n",
    "    combined_prompt_base = combine_prompts_and_base(response_1, response_2, response_3, base_prompt)\n",
    "    tailored_prompt = add_tasks(combined_prompt_base, task_data)\n",
    "    tailored_prompt = add_encodings(tailored_prompt, encoding_dicts)\n",
    "    \n",
    "    # Add similar-concept examples (train only)\n",
    "    tailored_prompt += f\"\\n\\nThis task involves the concept: **{predicted_concept}**.\"\n",
    "    tailored_prompt += concept_instruction\n",
    "\n",
    "    print(\"Built tailored prompt.\")\n",
    "\n",
    "    return tailored_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_program(program_text, actual_task_id, suffix=\"\"):\n",
    "    # Define the base and task-specific folder paths\n",
    "    base_folder = \"Candidate_programs_tailored_prompts\"\n",
    "    task_folder = os.path.join(base_folder, actual_task_id)\n",
    "    \n",
    "    # Create the task-specific folder if it doesn't exist\n",
    "    os.makedirs(task_folder, exist_ok=True)\n",
    "\n",
    "    # Remove ```python or ``` if present\n",
    "    cleaned_text = re.sub(r\"^```(?:python)?\\s*|```$\", \"\", program_text.strip(), flags=re.MULTILINE)\n",
    "\n",
    "    # Find the next available version number, excluding suffix for base counting\n",
    "    existing_files = os.listdir(task_folder)\n",
    "    version_numbers = [\n",
    "        int(re.search(r\"solution_v(\\d+)\", fname).group(1))\n",
    "        for fname in existing_files\n",
    "        if re.match(r\"solution_v\\d+\", fname)\n",
    "    ]\n",
    "    next_version = max(version_numbers, default=0) + 1\n",
    "    \n",
    "    # Define the full path to the new Python file with the suffix (if provided)\n",
    "    file_path = os.path.join(task_folder, f\"solution_v{next_version}{suffix}.py\")\n",
    "    \n",
    "    # Save the program text to the file\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(cleaned_text.strip())\n",
    "\n",
    "    print(f\"Saved program for task {actual_task_id} as version {next_version}{suffix}: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_programs(tailored_prompt, actual_task_id, amount):\n",
    "    # Create two programs (change range for n programs)\n",
    "    for i in range(amount):  # You can adjust the range to create more programs\n",
    "        response = call_gpt(tailored_prompt)\n",
    "        \n",
    "        # Save the generated program\n",
    "        save_program(response, actual_task_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_program(file_path):\n",
    "    \"\"\"Load and execute a Python program from a file.\"\"\"\n",
    "    spec = importlib.util.spec_from_file_location(\"program\", file_path)\n",
    "    program = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(program)\n",
    "    return program.solve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks if the code is valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_python_code(filepath):\n",
    "    \"\"\"Check if the Python file contains valid syntax.\"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            source = f.read()\n",
    "        ast.parse(source)\n",
    "        return True\n",
    "    except SyntaxError:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_programs(task_data, task_folder):\n",
    "    \"\"\"Evaluate programs and collect detailed candidate outputs for each demonstration pair.\"\"\"\n",
    "    programs = []\n",
    "    program_files = [f for f in os.listdir(task_folder) if f.endswith(\".py\")]\n",
    "\n",
    "    any_valid = False  # Track whether any valid programs exist\n",
    "\n",
    "    for program_file in program_files:\n",
    "        program_path = os.path.join(task_folder, program_file)\n",
    "\n",
    "        # Check if the program is valid Python code\n",
    "        if not is_valid_python_code(program_path):\n",
    "            print(f\"Deleting invalid file: {program_file}\")\n",
    "            os.remove(program_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            solve_function = load_program(program_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading program {program_file}: {e}\")\n",
    "            os.remove(program_path)\n",
    "            continue\n",
    "\n",
    "        any_valid = True  # At least one valid program found\n",
    "\n",
    "        details = []\n",
    "        correct_count = 0\n",
    "        total_pairs = len(task_data['train'])\n",
    "\n",
    "        for pair in task_data['train']:\n",
    "            input_grid = pair['input']\n",
    "            expected_output = pair['output']\n",
    "            try:\n",
    "                candidate_output = solve_function(input_grid)\n",
    "                if np.array_equal(np.array(candidate_output), np.array(expected_output)):\n",
    "                    correct_count += 1\n",
    "            except Exception as e:\n",
    "                candidate_output = f\"Error: {e}\"\n",
    "            details.append({\n",
    "                \"input\": input_grid,\n",
    "                \"candidate_output\": candidate_output,\n",
    "                \"expected_output\": expected_output\n",
    "            })\n",
    "\n",
    "        score = correct_count / total_pairs if total_pairs > 0 else 0\n",
    "        programs.append({\n",
    "            \"program_name\": program_file,\n",
    "            \"score\": score,\n",
    "            \"correct_pairs\": correct_count,\n",
    "            \"total_pairs\": total_pairs,\n",
    "            \"details\": details\n",
    "        })\n",
    "\n",
    "    return programs if any_valid else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of Revision Prompt and Revised Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revise_candidate_program(candidate_file_path, task_data, actual_task_id):\n",
    "    # Load candidate code text\n",
    "    with open(candidate_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        candidate_code_text = f.read()\n",
    "\n",
    "    # Load candidate's solve function\n",
    "    try:\n",
    "        solve_fn = load_program(candidate_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading program for revision: {e}\")\n",
    "        return\n",
    "\n",
    "    # Use the externally defined revision_prompt and add the generated code and demonstration pairs details\n",
    "    local_revision_prompt = revision_prompt + \"\\n\\nHere is the generated code:\\n\" + candidate_code_text + \"\\n\\nDemonstration Pairs:\\n\"\n",
    "\n",
    "    for i, pair in enumerate(task_data['train']):\n",
    "        try:\n",
    "            candidate_output = solve_fn(pair['input'])\n",
    "        except Exception as e:\n",
    "            candidate_output = f\"Error: {e}\"\n",
    "        local_revision_prompt += f\"{i+1}. Input: {pair['input']}\\n\"\n",
    "        local_revision_prompt += f\"   Expected Output: {pair['output']}\\n\"\n",
    "        local_revision_prompt += f\"   Generated Output: {candidate_output}\\n\"\n",
    "\n",
    "    local_revision_prompt += \"\\nPlease revise the code.\"\n",
    "\n",
    "    # Send the revision prompt to the LLM\n",
    "    revised_code = call_gpt(local_revision_prompt)\n",
    "\n",
    "    # Determine the revision level (e.g. _rev1, _rev2, ...) based on existing files\n",
    "    task_folder = os.path.join(\"Candidate_programs_tailored_prompts\", actual_task_id)\n",
    "    base_name = os.path.basename(candidate_file_path)\n",
    "    base_version_match = re.search(r\"solution_v(\\d+)\", base_name)\n",
    "    base_version = base_version_match.group(1) if base_version_match else \"1\"\n",
    "\n",
    "    # Count existing revisions for this version\n",
    "    existing_files = os.listdir(task_folder)\n",
    "    revision_count = len([\n",
    "        f for f in existing_files\n",
    "        if re.match(rf\"solution_v{base_version}_rev\\d+\\.py\", f)\n",
    "    ])\n",
    "    suffix = f\"_rev{revision_count + 1}\"\n",
    "\n",
    "    # Save revised program\n",
    "    save_program(revised_code, actual_task_id, suffix=suffix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identification of Best Programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_programs(evaluation_results, actual_task_id, n=2):\n",
    "    \"\"\"\n",
    "    Evaluates programs for a given task and returns the file paths for the top n programs based on demonstration pairs.\n",
    "    Always returns exactly n programs by sorting by score in descending order.\n",
    "    \"\"\"\n",
    "    # Sort programs by score descending; if scores are equal, the original order is preserved.\n",
    "    sorted_programs = sorted(evaluation_results, key=lambda x: x['score'], reverse=True)\n",
    "    task_folder = os.path.join(\"Candidate_programs_tailored_prompts\", actual_task_id)\n",
    "    best_program_files = [os.path.join(task_folder, prog['program_name']) for prog in sorted_programs[:n]]\n",
    "    for i in best_program_files:\n",
    "        print(f\"Best program: {i}\")\n",
    "    return best_program_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generation of Predictions on Test Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_predictions(task_data, actual_task_id, best_program_files):\n",
    "    \"\"\"\n",
    "    Loads the two best candidate programs from the specified file paths,\n",
    "    runs each one on every test input, and saves the generated outputs\n",
    "    in the submission file.\n",
    "    \n",
    "    Expects task_data to have a 'test' key with a list of test pairs,\n",
    "    where each pair is a dict containing an \"input\" key.\n",
    "    \n",
    "    Returns a submission dictionary of the form:\n",
    "    { actual_task_id: [ { \"attempt_1\": output_from_program1, \"attempt_2\": output_from_program2 }, ... ] }\n",
    "    \"\"\"\n",
    "    # Load the candidate solvers using the file paths.\n",
    "    best_solvers = [load_program(prog_file) for prog_file in best_program_files]\n",
    "    \n",
    "    predictions = []\n",
    "    # Iterate over each test pair.\n",
    "    for i, pair in enumerate(task_data[\"test\"]):\n",
    "        input_grid = pair[\"input\"]\n",
    "        attempt_predictions = {}\n",
    "        # Run each candidate solver on the test input.\n",
    "        for idx, solver in enumerate(best_solvers, start=1):\n",
    "            try:\n",
    "                output = solver(input_grid)\n",
    "            except Exception as e:\n",
    "                output = f\"Error: {e}\"\n",
    "            attempt_predictions[f\"attempt_{idx}\"] = output\n",
    "        predictions.append(attempt_predictions)\n",
    "    \n",
    "    submission = {str(actual_task_id): predictions}\n",
    "    \n",
    "    return submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built tailored prompt.\n",
      "Saved program for task 0607ce86 as version 1: Candidate_programs_tailored_prompts\\0607ce86\\solution_v1.py\n",
      "Saved program for task 0607ce86 as version 2: Candidate_programs_tailored_prompts\\0607ce86\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task 0607ce86 as version 3_rev1: Candidate_programs_tailored_prompts\\0607ce86\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task 0607ce86 as version 4_rev1: Candidate_programs_tailored_prompts\\0607ce86\\solution_v4_rev1.py\n",
      "Task 0607ce86 (1) evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts\\0607ce86\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts\\0607ce86\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task 0934a4d8 as version 1: Candidate_programs_tailored_prompts\\0934a4d8\\solution_v1.py\n",
      "Saved program for task 0934a4d8 as version 2: Candidate_programs_tailored_prompts\\0934a4d8\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task 0934a4d8 as version 3_rev1: Candidate_programs_tailored_prompts\\0934a4d8\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task 0934a4d8 as version 4_rev1: Candidate_programs_tailored_prompts\\0934a4d8\\solution_v4_rev1.py\n",
      "Task 0934a4d8 (2) evaluation results:\n",
      "Program solution_v1.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts\\0934a4d8\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts\\0934a4d8\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task 09c534e7 as version 1: Candidate_programs_tailored_prompts\\09c534e7\\solution_v1.py\n",
      "Saved program for task 09c534e7 as version 2: Candidate_programs_tailored_prompts\\09c534e7\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task 09c534e7 as version 3_rev1: Candidate_programs_tailored_prompts\\09c534e7\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task 09c534e7 as version 4_rev1: Candidate_programs_tailored_prompts\\09c534e7\\solution_v4_rev1.py\n",
      "Task 09c534e7 (3) evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts\\09c534e7\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts\\09c534e7\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task 0b17323b as version 1: Candidate_programs_tailored_prompts\\0b17323b\\solution_v1.py\n",
      "Saved program for task 0b17323b as version 2: Candidate_programs_tailored_prompts\\0b17323b\\solution_v2.py\n",
      "Task 0b17323b (4) evaluation results:\n",
      "Program solution_v1.py solved 2 out of 2 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 2 out of 2 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts\\0b17323b\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts\\0b17323b\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task 0c786b71 as version 1: Candidate_programs_tailored_prompts\\0c786b71\\solution_v1.py\n",
      "Saved program for task 0c786b71 as version 2: Candidate_programs_tailored_prompts\\0c786b71\\solution_v2.py\n",
      "Task 0c786b71 (5) evaluation results:\n",
      "Program solution_v1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts\\0c786b71\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts\\0c786b71\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task 137f0df0 as version 1: Candidate_programs_tailored_prompts\\137f0df0\\solution_v1.py\n",
      "Saved program for task 137f0df0 as version 2: Candidate_programs_tailored_prompts\\137f0df0\\solution_v2.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task 137f0df0 as version 3_rev1: Candidate_programs_tailored_prompts\\137f0df0\\solution_v3_rev1.py\n",
      "Task 137f0df0 (6) evaluation results:\n",
      "Program solution_v1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 1 out of 3 pairs. Score: 0.33\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts\\137f0df0\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts\\137f0df0\\solution_v3_rev1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task 15113be4 as version 1: Candidate_programs_tailored_prompts\\15113be4\\solution_v1.py\n",
      "Saved program for task 15113be4 as version 2: Candidate_programs_tailored_prompts\\15113be4\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task 15113be4 as version 3_rev1: Candidate_programs_tailored_prompts\\15113be4\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task 15113be4 as version 4_rev1: Candidate_programs_tailored_prompts\\15113be4\\solution_v4_rev1.py\n",
      "Task 15113be4 (7) evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts\\15113be4\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts\\15113be4\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task 17b80ad2 as version 1: Candidate_programs_tailored_prompts\\17b80ad2\\solution_v1.py\n",
      "Saved program for task 17b80ad2 as version 2: Candidate_programs_tailored_prompts\\17b80ad2\\solution_v2.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task 17b80ad2 as version 3_rev1: Candidate_programs_tailored_prompts\\17b80ad2\\solution_v3_rev1.py\n",
      "Task 17b80ad2 (8) evaluation results:\n",
      "Program solution_v1.py solved 4 out of 4 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 2 out of 4 pairs. Score: 0.50\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 2 out of 4 pairs. Score: 0.50\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts\\17b80ad2\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts\\17b80ad2\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task 17cae0c1 as version 1: Candidate_programs_tailored_prompts\\17cae0c1\\solution_v1.py\n",
      "Saved program for task 17cae0c1 as version 2: Candidate_programs_tailored_prompts\\17cae0c1\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task 17cae0c1 as version 3_rev1: Candidate_programs_tailored_prompts\\17cae0c1\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task 17cae0c1 as version 4_rev1: Candidate_programs_tailored_prompts\\17cae0c1\\solution_v4_rev1.py\n",
      "Task 17cae0c1 (9) evaluation results:\n",
      "Program solution_v1.py solved 3 out of 4 pairs. Score: 0.75\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 4 out of 4 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 4 out of 4 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts\\17cae0c1\\solution_v3_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts\\17cae0c1\\solution_v4_rev1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task 1c56ad9f as version 1: Candidate_programs_tailored_prompts\\1c56ad9f\\solution_v1.py\n",
      "Saved program for task 1c56ad9f as version 2: Candidate_programs_tailored_prompts\\1c56ad9f\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task 1c56ad9f as version 3_rev1: Candidate_programs_tailored_prompts\\1c56ad9f\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task 1c56ad9f as version 4_rev1: Candidate_programs_tailored_prompts\\1c56ad9f\\solution_v4_rev1.py\n",
      "Task 1c56ad9f (10) evaluation results:\n",
      "Program solution_v1.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 1 out of 4 pairs. Score: 0.25\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 2 out of 4 pairs. Score: 0.50\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts\\1c56ad9f\\solution_v3_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts\\1c56ad9f\\solution_v2.py\n"
     ]
    }
   ],
   "source": [
    "# Load tasks and API key\n",
    "tasks = load_tasks(\"evaluation_set\")\n",
    "load_api_key()\n",
    "\n",
    "# Stores predictions for all tasks\n",
    "final_submission = {} \n",
    "\n",
    "# Loop through each task (adjustable range)\n",
    "for i, task in enumerate(tasks[:10]):\n",
    "    actual_task_id = task[\"filename\"].split(\".\")[0]\n",
    "    \n",
    "    ### PROMPT CREATION ###\n",
    "    tailored_prompt = build_prompts(task['data'], actual_task_id)\n",
    "    create_programs(tailored_prompt, actual_task_id, amount=2)\n",
    "    \n",
    "    ### INITIAL EVALUATION ###\n",
    "    task_folder = os.path.join(\"Candidate_programs_tailored_prompts\", actual_task_id)\n",
    "    evaluation_results = evaluate_programs(task['data'], task_folder)\n",
    "    \n",
    "    while evaluation_results == 0:\n",
    "        create_programs(tailored_prompt, actual_task_id, amount=2)\n",
    "        evaluation_results = evaluate_programs(task['data'], task_folder)\n",
    "\n",
    "    ### FIRST REVISION: Revise all < 1 ###\n",
    "    for result in evaluation_results:\n",
    "        if result['score'] < 1:\n",
    "            candidate_file = os.path.join(task_folder, result['program_name'])\n",
    "            print(f\"Revising {result['program_name']}...\")\n",
    "            revise_candidate_program(candidate_file, task['data'], actual_task_id)\n",
    "\n",
    "    ### FINAL EVALUATION ###\n",
    "    evaluation_results_3 = evaluate_programs(task['data'], task_folder)\n",
    "    print(f\"Task {actual_task_id} ({i+1}) evaluation results:\")\n",
    "    for result in evaluation_results_3:\n",
    "        print(f\"Program {result['program_name']} solved {result['correct_pairs']} out of {result['total_pairs']} pairs. Score: {result['score']:.2f}\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "    ### PROGRAM SELECTION + PREDICTIONS ###\n",
    "    best_program_files = get_best_programs(evaluation_results_3, actual_task_id, n=2)\n",
    "    submission = generate_test_predictions(task['data'], actual_task_id, best_program_files)\n",
    "    final_submission.update(submission)\n",
    "\n",
    "# Final output file\n",
    "with open(\"submission_tailored_prompts.json\", \"w\") as f:\n",
    "    json.dump(final_submission, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Accuracy (for personal use if test outputs are present)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compares the submission.json file with the actual correct test outputs of a task and returns the accuracy.\n",
    "\n",
    "TODO: Add task categories and additionally show accuracies per category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_equal(a, b):\n",
    "    return json.dumps(a) == json.dumps(b)\n",
    "\n",
    "def compute_accuracy(submission_path, tasks_dict, task_concepts):\n",
    "    with open(submission_path, 'r') as f:\n",
    "        submission = json.load(f)\n",
    "\n",
    "    total_tasks = len(submission)\n",
    "    correct_tasks = 0\n",
    "\n",
    "    concept_totals = {}\n",
    "    concept_corrects = {}\n",
    "\n",
    "    for task_id, prediction_list in submission.items():\n",
    "        task_data = tasks_dict[task_id]\n",
    "        test_outputs = [test['output'] for test in task_data['test']]\n",
    "\n",
    "        all_test_cases_correct = True\n",
    "        for idx, expected_output in enumerate(test_outputs):\n",
    "            attempts = prediction_list[idx]\n",
    "            pred1 = attempts[\"attempt_1\"]\n",
    "            pred2 = attempts[\"attempt_2\"]\n",
    "\n",
    "            if not (are_equal(pred1, expected_output) or are_equal(pred2, expected_output)):\n",
    "                all_test_cases_correct = False\n",
    "                break\n",
    "\n",
    "        concept = task_concepts.get(task_id, \"Unknown Concept\")\n",
    "        concept_totals[concept] = concept_totals.get(concept, 0) + 1\n",
    "        if all_test_cases_correct:\n",
    "            correct_tasks += 1\n",
    "            concept_corrects[concept] = concept_corrects.get(concept, 0) + 1\n",
    "\n",
    "    accuracy = correct_tasks / total_tasks\n",
    "\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.2%}\\n\")\n",
    "\n",
    "    print(\"Accuracy per concept:\")\n",
    "    for concept, total in concept_totals.items():\n",
    "        correct = concept_corrects.get(concept, 0)\n",
    "        concept_accuracy = correct / total\n",
    "        print(f\"- {concept}: {correct}/{total} ({concept_accuracy:.2%})\")\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Accuracy: 50.00%\n",
      "\n",
      "Accuracy per concept:\n",
      "- CleanUp: 0/1 (0.00%)\n",
      "- ExtractObjects: 0/1 (0.00%)\n",
      "- FilledNotFilled: 0/1 (0.00%)\n",
      "- ExtendToBoundary: 3/3 (100.00%)\n",
      "- HorizontalVertical: 1/2 (50.00%)\n",
      "- Count: 0/1 (0.00%)\n",
      "- Order: 1/1 (100.00%)\n"
     ]
    }
   ],
   "source": [
    "with open(\"submission_tailored_prompts.json\") as f:\n",
    "    submission = json.load(f)\n",
    "\n",
    "tasks_dict = {task[\"filename\"].split(\".\")[0]: task[\"data\"] for task in tasks}\n",
    "\n",
    "accuracy = compute_accuracy(\"submission_tailored_prompts.json\", tasks_dict, task_concepts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are visual observations of the task that may help inform your implementation:\n",
      "- four distinct colors: 3 (green), 2 (red), 5 (grey), 8 (light-blue)  \n",
      "- uniform zero background in all inputs  \n",
      "- horizontal stripes of color at fixed rows (green: 4,7,10; red: 3,13; grey: 2,5,8,11; light-blue: 2,13)  \n",
      "- vertical bars of same color at consistent columns per puzzle (green cols 3,7,11; red cols 3,8; grey cols 4,7,8,11; light-blue cols 4,6,8)  \n",
      "- stripes and bars form hollow rectangular “rings”  \n",
      "- each puzzle shows repeated stripe/bar pattern (green/grey three bars, red two bars, light-blue three bars)  \n",
      "- no other colored pixels or border elements  \n",
      "- outputs preserve stripe rows but shift bar columns inward/outward on alternating stripes  \n",
      "- count of stripes equal to number of bar groups per color  \n",
      "- perfect left–right symmetry in all shapes\n",
      "\n",
      "Here are the transformation rules that have been identified based on the task:\n",
      "1. Each colored frame’s horizontal stripes stay on their original rows, but its vertical bars are slid one column inward on every other stripe and one column outward on the alternating stripes.  \n",
      "2. In other words, successive horizontal bands act as anchors, and the paired or tripled vertical stems shift toward the center on odd-indexed stripes and back toward the border on even‐indexed stripes.  \n",
      "3. The full horizontal runs remain intact, and only the vertical segments’ column indices change by ±1 in an alternating zigzag.  \n",
      "4. This yields a stepped or diagonally offset version of each rectangular ring while preserving perfect left–right symmetry.\n",
      "    \n",
      "Here is a reflection on how you might implement a solution to this task in Python:\n",
      "I would start by scanning the grid for non‐zero pixels and grouping them by color, then within each color group separating the long horizontal stripes (by detecting runs across many columns) from the vertical stem segments (by constant column runs). Sorting the horizontal stripes by their row index gives me the anchor bands, and for each color I’d list the paired or tripled bar columns and compute the center of symmetry. Iterating over the stripes top‐down, I’d shift each bar list alternately ±1 column toward or away from that center, reassembling the output nonzero coordinates. A key challenge to test is ensuring the inward/outward direction is always relative to the same center reference and handling any potential off‐by‐one when stripe counts are odd.\n",
      "\n",
      "Write a Python function that correctly transforms each input grid into its corresponding output grid based on the given examples.\n",
      "\n",
      "- ONLY return code. No explanations or anything other than code.\n",
      "- The function must be named: `solve(grid: List[List[int]]) -> List[List[int]]`\n",
      "- Use only pure Python — do not import or use libraries like NumPy\n",
      "- Do not include comments, explanations, or print statements\n",
      "- Do not hard-code values or specific grid sizes — the function must generalize based on the patterns in the examples\n",
      "- The function must return a plain 2D list of integers with consistent row lengths (List[List[int]])\n",
      "- Do not return arrays, nested arrays, floats, or 3D structures\n",
      "- Ensure your solution works for all provided input-output pairs\n",
      "\n",
      "Here are the demonstration pairs (JSON data):\n",
      "\n",
      "Train Input 1: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0], [0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0], [0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0], [0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0], [0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0], [0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0], [0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Train Output 1: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0], [0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0], [0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0], [0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0], [0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0], [0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0], [0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "\n",
      "Train Input 2: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Train Output 2: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], [0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0], [0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0], [0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "\n",
      "Train Input 3: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0], [0, 0, 0, 0, 5, 0, 0, 5, 5, 0, 0, 5, 0, 0, 0], [0, 0, 0, 0, 5, 0, 0, 5, 5, 0, 0, 5, 0, 0, 0], [0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0], [0, 0, 0, 0, 5, 0, 0, 5, 5, 0, 0, 5, 0, 0, 0], [0, 0, 0, 0, 5, 0, 0, 5, 5, 0, 0, 5, 0, 0, 0], [0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0], [0, 0, 0, 0, 5, 0, 0, 5, 5, 0, 0, 5, 0, 0, 0], [0, 0, 0, 0, 5, 0, 0, 5, 5, 0, 0, 5, 0, 0, 0], [0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Train Output 3: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0, 0], [0, 0, 0, 0, 5, 0, 0, 5, 5, 0, 0, 5, 0, 0, 0], [0, 0, 0, 0, 0, 5, 0, 0, 5, 5, 0, 0, 5, 0, 0], [0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0], [0, 0, 0, 5, 0, 0, 5, 5, 0, 0, 5, 0, 0, 0, 0], [0, 0, 0, 0, 5, 0, 0, 5, 5, 0, 0, 5, 0, 0, 0], [0, 0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0], [0, 0, 0, 0, 5, 0, 0, 5, 5, 0, 0, 5, 0, 0, 0], [0, 0, 0, 5, 0, 0, 5, 5, 0, 0, 5, 0, 0, 0, 0], [0, 0, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "\n",
      "Train Input 4: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "Train Output 4: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0], [0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0], [0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0], [0, 0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 8, 0, 8, 0, 8, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 8, 8, 8, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "\n",
      "\n",
      "Encoding used: nonzero_coords\n",
      "Explanation: This encoding lists only the non-zero cells as dictionaries containing their row, column, and value.\n",
      "\n",
      "Here are the demonstration pairs (encoded):\n",
      "\n",
      "Train Input 1: [{'row': 4, 'col': 3, 'val': 3}, {'row': 4, 'col': 4, 'val': 3}, {'row': 4, 'col': 5, 'val': 3}, {'row': 4, 'col': 6, 'val': 3}, {'row': 4, 'col': 7, 'val': 3}, {'row': 4, 'col': 8, 'val': 3}, {'row': 4, 'col': 9, 'val': 3}, {'row': 4, 'col': 10, 'val': 3}, {'row': 4, 'col': 11, 'val': 3}, {'row': 5, 'col': 3, 'val': 3}, {'row': 5, 'col': 7, 'val': 3}, {'row': 5, 'col': 11, 'val': 3}, {'row': 6, 'col': 3, 'val': 3}, {'row': 6, 'col': 7, 'val': 3}, {'row': 6, 'col': 11, 'val': 3}, {'row': 7, 'col': 3, 'val': 3}, {'row': 7, 'col': 4, 'val': 3}, {'row': 7, 'col': 5, 'val': 3}, {'row': 7, 'col': 6, 'val': 3}, {'row': 7, 'col': 7, 'val': 3}, {'row': 7, 'col': 8, 'val': 3}, {'row': 7, 'col': 9, 'val': 3}, {'row': 7, 'col': 10, 'val': 3}, {'row': 7, 'col': 11, 'val': 3}, {'row': 8, 'col': 3, 'val': 3}, {'row': 8, 'col': 7, 'val': 3}, {'row': 8, 'col': 11, 'val': 3}, {'row': 9, 'col': 3, 'val': 3}, {'row': 9, 'col': 7, 'val': 3}, {'row': 9, 'col': 11, 'val': 3}, {'row': 10, 'col': 3, 'val': 3}, {'row': 10, 'col': 4, 'val': 3}, {'row': 10, 'col': 5, 'val': 3}, {'row': 10, 'col': 6, 'val': 3}, {'row': 10, 'col': 7, 'val': 3}, {'row': 10, 'col': 8, 'val': 3}, {'row': 10, 'col': 9, 'val': 3}, {'row': 10, 'col': 10, 'val': 3}, {'row': 10, 'col': 11, 'val': 3}]\n",
      "Train Output 1: [{'row': 4, 'col': 3, 'val': 3}, {'row': 4, 'col': 4, 'val': 3}, {'row': 4, 'col': 5, 'val': 3}, {'row': 4, 'col': 6, 'val': 3}, {'row': 4, 'col': 7, 'val': 3}, {'row': 4, 'col': 8, 'val': 3}, {'row': 4, 'col': 9, 'val': 3}, {'row': 4, 'col': 10, 'val': 3}, {'row': 4, 'col': 11, 'val': 3}, {'row': 5, 'col': 2, 'val': 3}, {'row': 5, 'col': 6, 'val': 3}, {'row': 5, 'col': 10, 'val': 3}, {'row': 6, 'col': 3, 'val': 3}, {'row': 6, 'col': 7, 'val': 3}, {'row': 6, 'col': 11, 'val': 3}, {'row': 7, 'col': 4, 'val': 3}, {'row': 7, 'col': 5, 'val': 3}, {'row': 7, 'col': 6, 'val': 3}, {'row': 7, 'col': 7, 'val': 3}, {'row': 7, 'col': 8, 'val': 3}, {'row': 7, 'col': 9, 'val': 3}, {'row': 7, 'col': 10, 'val': 3}, {'row': 7, 'col': 11, 'val': 3}, {'row': 7, 'col': 12, 'val': 3}, {'row': 8, 'col': 3, 'val': 3}, {'row': 8, 'col': 7, 'val': 3}, {'row': 8, 'col': 11, 'val': 3}, {'row': 9, 'col': 2, 'val': 3}, {'row': 9, 'col': 6, 'val': 3}, {'row': 9, 'col': 10, 'val': 3}, {'row': 10, 'col': 3, 'val': 3}, {'row': 10, 'col': 4, 'val': 3}, {'row': 10, 'col': 5, 'val': 3}, {'row': 10, 'col': 6, 'val': 3}, {'row': 10, 'col': 7, 'val': 3}, {'row': 10, 'col': 8, 'val': 3}, {'row': 10, 'col': 9, 'val': 3}, {'row': 10, 'col': 10, 'val': 3}, {'row': 10, 'col': 11, 'val': 3}]\n",
      "\n",
      "Train Input 2: [{'row': 3, 'col': 3, 'val': 2}, {'row': 3, 'col': 4, 'val': 2}, {'row': 3, 'col': 5, 'val': 2}, {'row': 3, 'col': 6, 'val': 2}, {'row': 3, 'col': 7, 'val': 2}, {'row': 3, 'col': 8, 'val': 2}, {'row': 4, 'col': 3, 'val': 2}, {'row': 4, 'col': 8, 'val': 2}, {'row': 5, 'col': 3, 'val': 2}, {'row': 5, 'col': 8, 'val': 2}, {'row': 6, 'col': 3, 'val': 2}, {'row': 6, 'col': 8, 'val': 2}, {'row': 7, 'col': 3, 'val': 2}, {'row': 7, 'col': 8, 'val': 2}, {'row': 8, 'col': 3, 'val': 2}, {'row': 8, 'col': 8, 'val': 2}, {'row': 9, 'col': 3, 'val': 2}, {'row': 9, 'col': 8, 'val': 2}, {'row': 10, 'col': 3, 'val': 2}, {'row': 10, 'col': 8, 'val': 2}, {'row': 11, 'col': 3, 'val': 2}, {'row': 11, 'col': 8, 'val': 2}, {'row': 12, 'col': 3, 'val': 2}, {'row': 12, 'col': 8, 'val': 2}, {'row': 13, 'col': 3, 'val': 2}, {'row': 13, 'col': 4, 'val': 2}, {'row': 13, 'col': 5, 'val': 2}, {'row': 13, 'col': 6, 'val': 2}, {'row': 13, 'col': 7, 'val': 2}, {'row': 13, 'col': 8, 'val': 2}]\n",
      "Train Output 2: [{'row': 3, 'col': 3, 'val': 2}, {'row': 3, 'col': 4, 'val': 2}, {'row': 3, 'col': 5, 'val': 2}, {'row': 3, 'col': 6, 'val': 2}, {'row': 3, 'col': 7, 'val': 2}, {'row': 3, 'col': 8, 'val': 2}, {'row': 4, 'col': 2, 'val': 2}, {'row': 4, 'col': 7, 'val': 2}, {'row': 5, 'col': 3, 'val': 2}, {'row': 5, 'col': 8, 'val': 2}, {'row': 6, 'col': 4, 'val': 2}, {'row': 6, 'col': 9, 'val': 2}, {'row': 7, 'col': 3, 'val': 2}, {'row': 7, 'col': 8, 'val': 2}, {'row': 8, 'col': 2, 'val': 2}, {'row': 8, 'col': 7, 'val': 2}, {'row': 9, 'col': 3, 'val': 2}, {'row': 9, 'col': 8, 'val': 2}, {'row': 10, 'col': 4, 'val': 2}, {'row': 10, 'col': 9, 'val': 2}, {'row': 11, 'col': 3, 'val': 2}, {'row': 11, 'col': 8, 'val': 2}, {'row': 12, 'col': 2, 'val': 2}, {'row': 12, 'col': 7, 'val': 2}, {'row': 13, 'col': 3, 'val': 2}, {'row': 13, 'col': 4, 'val': 2}, {'row': 13, 'col': 5, 'val': 2}, {'row': 13, 'col': 6, 'val': 2}, {'row': 13, 'col': 7, 'val': 2}, {'row': 13, 'col': 8, 'val': 2}]\n",
      "\n",
      "Train Input 3: [{'row': 2, 'col': 4, 'val': 5}, {'row': 2, 'col': 5, 'val': 5}, {'row': 2, 'col': 6, 'val': 5}, {'row': 2, 'col': 7, 'val': 5}, {'row': 2, 'col': 8, 'val': 5}, {'row': 2, 'col': 9, 'val': 5}, {'row': 2, 'col': 10, 'val': 5}, {'row': 2, 'col': 11, 'val': 5}, {'row': 3, 'col': 4, 'val': 5}, {'row': 3, 'col': 7, 'val': 5}, {'row': 3, 'col': 8, 'val': 5}, {'row': 3, 'col': 11, 'val': 5}, {'row': 4, 'col': 4, 'val': 5}, {'row': 4, 'col': 7, 'val': 5}, {'row': 4, 'col': 8, 'val': 5}, {'row': 4, 'col': 11, 'val': 5}, {'row': 5, 'col': 4, 'val': 5}, {'row': 5, 'col': 5, 'val': 5}, {'row': 5, 'col': 6, 'val': 5}, {'row': 5, 'col': 7, 'val': 5}, {'row': 5, 'col': 8, 'val': 5}, {'row': 5, 'col': 9, 'val': 5}, {'row': 5, 'col': 10, 'val': 5}, {'row': 5, 'col': 11, 'val': 5}, {'row': 6, 'col': 4, 'val': 5}, {'row': 6, 'col': 7, 'val': 5}, {'row': 6, 'col': 8, 'val': 5}, {'row': 6, 'col': 11, 'val': 5}, {'row': 7, 'col': 4, 'val': 5}, {'row': 7, 'col': 7, 'val': 5}, {'row': 7, 'col': 8, 'val': 5}, {'row': 7, 'col': 11, 'val': 5}, {'row': 8, 'col': 4, 'val': 5}, {'row': 8, 'col': 5, 'val': 5}, {'row': 8, 'col': 6, 'val': 5}, {'row': 8, 'col': 7, 'val': 5}, {'row': 8, 'col': 8, 'val': 5}, {'row': 8, 'col': 9, 'val': 5}, {'row': 8, 'col': 10, 'val': 5}, {'row': 8, 'col': 11, 'val': 5}, {'row': 9, 'col': 4, 'val': 5}, {'row': 9, 'col': 7, 'val': 5}, {'row': 9, 'col': 8, 'val': 5}, {'row': 9, 'col': 11, 'val': 5}, {'row': 10, 'col': 4, 'val': 5}, {'row': 10, 'col': 7, 'val': 5}, {'row': 10, 'col': 8, 'val': 5}, {'row': 10, 'col': 11, 'val': 5}, {'row': 11, 'col': 4, 'val': 5}, {'row': 11, 'col': 5, 'val': 5}, {'row': 11, 'col': 6, 'val': 5}, {'row': 11, 'col': 7, 'val': 5}, {'row': 11, 'col': 8, 'val': 5}, {'row': 11, 'col': 9, 'val': 5}, {'row': 11, 'col': 10, 'val': 5}, {'row': 11, 'col': 11, 'val': 5}]\n",
      "Train Output 3: [{'row': 2, 'col': 3, 'val': 5}, {'row': 2, 'col': 4, 'val': 5}, {'row': 2, 'col': 5, 'val': 5}, {'row': 2, 'col': 6, 'val': 5}, {'row': 2, 'col': 7, 'val': 5}, {'row': 2, 'col': 8, 'val': 5}, {'row': 2, 'col': 9, 'val': 5}, {'row': 2, 'col': 10, 'val': 5}, {'row': 3, 'col': 4, 'val': 5}, {'row': 3, 'col': 7, 'val': 5}, {'row': 3, 'col': 8, 'val': 5}, {'row': 3, 'col': 11, 'val': 5}, {'row': 4, 'col': 5, 'val': 5}, {'row': 4, 'col': 8, 'val': 5}, {'row': 4, 'col': 9, 'val': 5}, {'row': 4, 'col': 12, 'val': 5}, {'row': 5, 'col': 4, 'val': 5}, {'row': 5, 'col': 5, 'val': 5}, {'row': 5, 'col': 6, 'val': 5}, {'row': 5, 'col': 7, 'val': 5}, {'row': 5, 'col': 8, 'val': 5}, {'row': 5, 'col': 9, 'val': 5}, {'row': 5, 'col': 10, 'val': 5}, {'row': 5, 'col': 11, 'val': 5}, {'row': 6, 'col': 3, 'val': 5}, {'row': 6, 'col': 6, 'val': 5}, {'row': 6, 'col': 7, 'val': 5}, {'row': 6, 'col': 10, 'val': 5}, {'row': 7, 'col': 4, 'val': 5}, {'row': 7, 'col': 7, 'val': 5}, {'row': 7, 'col': 8, 'val': 5}, {'row': 7, 'col': 11, 'val': 5}, {'row': 8, 'col': 5, 'val': 5}, {'row': 8, 'col': 6, 'val': 5}, {'row': 8, 'col': 7, 'val': 5}, {'row': 8, 'col': 8, 'val': 5}, {'row': 8, 'col': 9, 'val': 5}, {'row': 8, 'col': 10, 'val': 5}, {'row': 8, 'col': 11, 'val': 5}, {'row': 8, 'col': 12, 'val': 5}, {'row': 9, 'col': 4, 'val': 5}, {'row': 9, 'col': 7, 'val': 5}, {'row': 9, 'col': 8, 'val': 5}, {'row': 9, 'col': 11, 'val': 5}, {'row': 10, 'col': 3, 'val': 5}, {'row': 10, 'col': 6, 'val': 5}, {'row': 10, 'col': 7, 'val': 5}, {'row': 10, 'col': 10, 'val': 5}, {'row': 11, 'col': 4, 'val': 5}, {'row': 11, 'col': 5, 'val': 5}, {'row': 11, 'col': 6, 'val': 5}, {'row': 11, 'col': 7, 'val': 5}, {'row': 11, 'col': 8, 'val': 5}, {'row': 11, 'col': 9, 'val': 5}, {'row': 11, 'col': 10, 'val': 5}, {'row': 11, 'col': 11, 'val': 5}]\n",
      "\n",
      "Train Input 4: [{'row': 2, 'col': 4, 'val': 8}, {'row': 2, 'col': 5, 'val': 8}, {'row': 2, 'col': 6, 'val': 8}, {'row': 2, 'col': 7, 'val': 8}, {'row': 2, 'col': 8, 'val': 8}, {'row': 3, 'col': 4, 'val': 8}, {'row': 3, 'col': 6, 'val': 8}, {'row': 3, 'col': 8, 'val': 8}, {'row': 4, 'col': 4, 'val': 8}, {'row': 4, 'col': 6, 'val': 8}, {'row': 4, 'col': 8, 'val': 8}, {'row': 5, 'col': 4, 'val': 8}, {'row': 5, 'col': 6, 'val': 8}, {'row': 5, 'col': 8, 'val': 8}, {'row': 6, 'col': 4, 'val': 8}, {'row': 6, 'col': 6, 'val': 8}, {'row': 6, 'col': 8, 'val': 8}, {'row': 7, 'col': 4, 'val': 8}, {'row': 7, 'col': 6, 'val': 8}, {'row': 7, 'col': 8, 'val': 8}, {'row': 8, 'col': 4, 'val': 8}, {'row': 8, 'col': 6, 'val': 8}, {'row': 8, 'col': 8, 'val': 8}, {'row': 9, 'col': 4, 'val': 8}, {'row': 9, 'col': 6, 'val': 8}, {'row': 9, 'col': 8, 'val': 8}, {'row': 10, 'col': 4, 'val': 8}, {'row': 10, 'col': 6, 'val': 8}, {'row': 10, 'col': 8, 'val': 8}, {'row': 11, 'col': 4, 'val': 8}, {'row': 11, 'col': 6, 'val': 8}, {'row': 11, 'col': 8, 'val': 8}, {'row': 12, 'col': 4, 'val': 8}, {'row': 12, 'col': 6, 'val': 8}, {'row': 12, 'col': 8, 'val': 8}, {'row': 13, 'col': 4, 'val': 8}, {'row': 13, 'col': 5, 'val': 8}, {'row': 13, 'col': 6, 'val': 8}, {'row': 13, 'col': 7, 'val': 8}, {'row': 13, 'col': 8, 'val': 8}]\n",
      "Train Output 4: [{'row': 2, 'col': 5, 'val': 8}, {'row': 2, 'col': 6, 'val': 8}, {'row': 2, 'col': 7, 'val': 8}, {'row': 2, 'col': 8, 'val': 8}, {'row': 2, 'col': 9, 'val': 8}, {'row': 3, 'col': 4, 'val': 8}, {'row': 3, 'col': 6, 'val': 8}, {'row': 3, 'col': 8, 'val': 8}, {'row': 4, 'col': 3, 'val': 8}, {'row': 4, 'col': 5, 'val': 8}, {'row': 4, 'col': 7, 'val': 8}, {'row': 5, 'col': 4, 'val': 8}, {'row': 5, 'col': 6, 'val': 8}, {'row': 5, 'col': 8, 'val': 8}, {'row': 6, 'col': 5, 'val': 8}, {'row': 6, 'col': 7, 'val': 8}, {'row': 6, 'col': 9, 'val': 8}, {'row': 7, 'col': 4, 'val': 8}, {'row': 7, 'col': 6, 'val': 8}, {'row': 7, 'col': 8, 'val': 8}, {'row': 8, 'col': 3, 'val': 8}, {'row': 8, 'col': 5, 'val': 8}, {'row': 8, 'col': 7, 'val': 8}, {'row': 9, 'col': 4, 'val': 8}, {'row': 9, 'col': 6, 'val': 8}, {'row': 9, 'col': 8, 'val': 8}, {'row': 10, 'col': 5, 'val': 8}, {'row': 10, 'col': 7, 'val': 8}, {'row': 10, 'col': 9, 'val': 8}, {'row': 11, 'col': 4, 'val': 8}, {'row': 11, 'col': 6, 'val': 8}, {'row': 11, 'col': 8, 'val': 8}, {'row': 12, 'col': 3, 'val': 8}, {'row': 12, 'col': 5, 'val': 8}, {'row': 12, 'col': 7, 'val': 8}, {'row': 13, 'col': 4, 'val': 8}, {'row': 13, 'col': 5, 'val': 8}, {'row': 13, 'col': 6, 'val': 8}, {'row': 13, 'col': 7, 'val': 8}, {'row': 13, 'col': 8, 'val': 8}]\n",
      "\n",
      "\n",
      "This task involves the concept: **HorizontalVertical**.\n",
      "\n",
      "Here are a few examples with the same concept:\n",
      "\n",
      "Concept Train Input 1: [[0, 2, 2, 2, 0, 0, 0, 0, 0, 0], [0, 2, 0, 2, 0, 0, 0, 0, 0, 0], [0, 2, 0, 2, 0, 0, 0, 0, 0, 0], [0, 2, 0, 2, 0, 0, 0, 0, 0, 0], [0, 2, 2, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 4, 4, 4, 4, 0, 0], [0, 0, 0, 4, 0, 0, 0, 4, 0, 0], [0, 0, 0, 4, 4, 4, 4, 4, 0, 0]]\n",
      "Concept Train Output 1: [[0, 2, 2, 2, 0, 0, 0, 0, 0, 0], [0, 2, 3, 2, 0, 0, 0, 0, 0, 0], [0, 2, 3, 2, 0, 0, 0, 0, 0, 0], [0, 2, 3, 2, 0, 0, 0, 0, 0, 0], [0, 2, 2, 2, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 4, 4, 4, 4, 4, 0, 0], [0, 0, 0, 4, 7, 7, 7, 4, 0, 0], [0, 0, 0, 4, 4, 4, 4, 4, 0, 0]]\n",
      "\n",
      "Concept Train Input 2: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 4], [0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 4, 0, 4], [0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 4, 0, 4], [0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 4, 4, 4], [0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7], [0, 0, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 0, 7], [0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 0, 7, 0, 7], [0, 0, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 0, 7], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7]]\n",
      "Concept Train Output 2: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 3, 4], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 3, 4], [0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 4, 3, 4], [0, 2, 7, 7, 7, 7, 7, 7, 2, 0, 0, 4, 3, 4], [0, 2, 7, 7, 7, 7, 7, 7, 2, 0, 0, 4, 4, 4], [0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 3, 7], [0, 0, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 3, 7], [0, 0, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 3, 7], [0, 0, 7, 7, 7, 7, 7, 7, 7, 0, 0, 7, 3, 7], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 3, 7], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tailored_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
