{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline: LLM-powered program generation for solving ARC-AGI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import ast\n",
    "import re\n",
    "import importlib.util\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system prompt contains basic information essential for every prompt sent to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a visual reasoning and Python programming expert solving ARC-AGI (Abstraction and Reasoning Corpus - Artificial General Intelligence) tasks.\n",
    "\n",
    "Each integer in the grid represents a color:\n",
    "0 = black, 1 = blue, 2 = red, 3 = green, 4 = yellow,\n",
    "5 = grey, 6 = pink, 7 = orange, 8 = light blue, 9 = brown.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following prompt tasks the LLM with program generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = \"\"\"\n",
    "Write a Python function that correctly transforms each input grid into its corresponding output grid based on the given examples.\n",
    "\n",
    "- ONLY return code. No explanations or anything other than code.\n",
    "- The function must be named: `solve(grid: List[List[int]]) -> List[List[int]]`\n",
    "- Use only pure Python — do not import or use libraries like NumPy\n",
    "- Do not include comments, explanations, or print statements\n",
    "- Do not hard-code values or specific grid sizes — the function must generalize based on the patterns in the examples\n",
    "- The function must return a plain 2D list of integers with consistent row lengths (List[List[int]])\n",
    "- Do not return arrays, nested arrays, floats, or 3D structures\n",
    "- Ensure your solution works for all provided input-output pairs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Write a Python function that correctly transforms each input grid into its corresponding output grid based on the given examples.\n",
      "\n",
      "- ONLY return code. No explanations or anything other than code.\n",
      "- The function must be named: `solve(grid: List[List[int]]) -> List[List[int]]`\n",
      "- Use only pure Python — do not import or use libraries like NumPy\n",
      "- Do not include comments, explanations, or print statements\n",
      "- Do not hard-code values or specific grid sizes — the function must generalize based on the patterns in the examples\n",
      "- The function must return a plain 2D list of integers with consistent row lengths (List[List[int]])\n",
      "- Do not return arrays, nested arrays, floats, or 3D structures\n",
      "- Ensure your solution works for all provided input-output pairs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(base_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following prompt tasks the LLM to describe visual observations of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = \"\"\"\n",
    "List visual observations from the training pairs.\n",
    "\n",
    "- Use bullet points (max 10).\n",
    "- Focus on colors, shapes, object counts, positions, and fixed elements (e.g., anchors, borders, gray blocks).\n",
    "- Mention groupings or repeated patterns if visible.\n",
    "- Avoid reasoning or explanations.\n",
    "- Be concise. No full sentences, no extra formatting.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List visual observations from the training pairs.\n",
      "\n",
      "- Use bullet points (max 10).\n",
      "- Focus on colors, shapes, object counts, positions, and fixed elements (e.g., anchors, borders, gray blocks).\n",
      "- Mention groupings or repeated patterns if visible.\n",
      "- Avoid reasoning or explanations.\n",
      "- Be concise. No full sentences, no extra formatting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following prompt tasks the LLM with describing the tasks underlying transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = \"\"\"\n",
    "Describe the transformation(s) from input to output grids.\n",
    "\n",
    "- Use 3 to 5 short sentences.\n",
    "- Focus on what changes: movement, color, shape, duplication, stacking, mirroring, etc.\n",
    "- Mention any use of anchors, fixed positions, or reference structures.\n",
    "- If applicable, describe how objects are grouped, reassigned, or reorganized.\n",
    "- Avoid implementation hints or code.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Describe the transformation(s) from input to output grids.\n",
      "\n",
      "- Use 3 to 5 short sentences.\n",
      "- Focus on what changes: movement, color, shape, duplication, stacking, mirroring, etc.\n",
      "- Mention any use of anchors, fixed positions, or reference structures.\n",
      "- If applicable, describe how objects are grouped, reassigned, or reorganized.\n",
      "- Avoid implementation hints or code.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following prompt tasks the LLM to reflect a possible implementation of the transformation in Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3 = \"\"\"\n",
    "Reflect on how you would solve the task in Python.\n",
    "\n",
    "- Use 3 to 5 sentences.\n",
    "- Describe the main approach, such as identifying anchors, grouping objects, and applying transformations.\n",
    "- Mention steps like scanning for fixed elements, sorting, or aligning data.\n",
    "- Call out any challenges or unclear rules you would need to test for.\n",
    "- Do not return code or pseudocode.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reflect on how you would solve the task in Python.\n",
      "\n",
      "- Use 3 to 5 sentences.\n",
      "- Describe the main approach, such as identifying anchors, grouping objects, and applying transformations.\n",
      "- Mention steps like scanning for fixed elements, sorting, or aligning data.\n",
      "- Call out any challenges or unclear rules you would need to test for.\n",
      "- Do not return code or pseudocode.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revision Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following prompt tasks the LLM with revising the Python implementations it created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "revision_prompt = \"\"\"\n",
    "In the following you'll receive a Python function that attempted to solve the following task. It didn't succeed and you are tasked with fixing it.\n",
    "\n",
    "- The function must be named: `solve(grid: List[List[int]]) -> List[List[int]]`\n",
    "- Include only the code and necessary imports (e.g., `import numpy as np`)\n",
    "- Do not include comments, explanations, or print statements\n",
    "- Do not hard-code values or specific grid sizes — the function must generalize based on the patterns in the examples\n",
    "- Ensure your solution works for all provided input-output pairs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In the following you'll receive a Python function that attempted to solve the following task. It didn't succeed and you are tasked with fixing it.\n",
      "\n",
      "- The function must be named: `solve(grid: List[List[int]]) -> List[List[int]]`\n",
      "- Include only the code and necessary imports (e.g., `import numpy as np`)\n",
      "- Do not include comments, explanations, or print statements\n",
      "- Do not hard-code values or specific grid sizes — the function must generalize based on the patterns in the examples\n",
      "- Ensure your solution works for all provided input-output pairs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(revision_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Prompt (Prompt 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following prompt tasks the LLM to classify the given task to one of the 16 concepts of the ConceptARC dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_prompt = \"\"\"\n",
    "You will receive a set of demonstration pairs (input and output grids) from a visual reasoning task.\n",
    "\n",
    "Your task is to classify the transformation into **one of the following 16 concepts**:\n",
    "\n",
    "- AboveBelow - Objects or patterns are arranged vertically, with relationships defined by what's above or below something else.\n",
    "- Center - Elements are moved to or arranged around the center of the grid.\n",
    "- CleanUp - The task removes noise or extraneous elements to leave a cleaner or more regular structure.\n",
    "- CompleteShape - A partial or broken shape is completed to form a full geometric object.\n",
    "- Copy - A shape or pattern is duplicated, often to another location in the grid.\n",
    "- Count - The number of certain elements is counted to determine placement, output quantity, or transformation.\n",
    "- ExtendToBoundary - Shapes or lines are extended until they touch the edge of the grid.\n",
    "- ExtractObjects - Specific objects are isolated and copied or transformed while others are ignored.\n",
    "- FilledNotFilled - The task distinguishes between filled and hollow shapes or fills in uncolored areas.\n",
    "- HorizontalVertical - Patterns follow or are transformed along horizontal or vertical axes, often involving symmetry or alignment.\n",
    "- InsideOutside - A relationship is determined based on whether elements are inside or outside a defined boundary.\n",
    "- MoveToBoundary - Objects are shifted to the nearest edge of the grid without rotation or change in shape.\n",
    "- Order - Items are rearranged according to size, color, frequency, or another ordinal property.\n",
    "- SameDifferent - Objects are retained or manipulated based on whether they match or differ in some attribute (e.g., color, shape).\n",
    "- TopBottom2D - A flat 2D interpretation of objects where the top and bottom halves of the grid are compared or modified.\n",
    "- TopBottom3D - The task simulates a 3D stacking or layering behavior, such as viewing objects from above or combining vertical slices.\n",
    "\n",
    "Instructions:\n",
    "- Respond ONLY with the exact name of the matching concept from the list above.\n",
    "- Do not explain your answer, just return the concept.\n",
    "- If uncertain, choose the concept that fits best based on the input-output transformations.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will receive a set of demonstration pairs (input and output grids) from a visual reasoning task.\n",
      "\n",
      "Your task is to classify the transformation into **one of the following 16 concepts**:\n",
      "\n",
      "- AboveBelow - Objects or patterns are arranged vertically, with relationships defined by what's above or below something else.\n",
      "- Center - Elements are moved to or arranged around the center of the grid.\n",
      "- CleanUp - The task removes noise or extraneous elements to leave a cleaner or more regular structure.\n",
      "- CompleteShape - A partial or broken shape is completed to form a full geometric object.\n",
      "- Copy - A shape or pattern is duplicated, often to another location in the grid.\n",
      "- Count - The number of certain elements is counted to determine placement, output quantity, or transformation.\n",
      "- ExtendToBoundary - Shapes or lines are extended until they touch the edge of the grid.\n",
      "- ExtractObjects - Specific objects are isolated and copied or transformed while others are ignored.\n",
      "- FilledNotFilled - The task distinguishes between filled and hollow shapes or fills in uncolored areas.\n",
      "- HorizontalVertical - Patterns follow or are transformed along horizontal or vertical axes, often involving symmetry or alignment.\n",
      "- InsideOutside - A relationship is determined based on whether elements are inside or outside a defined boundary.\n",
      "- MoveToBoundary - Objects are shifted to the nearest edge of the grid without rotation or change in shape.\n",
      "- Order - Items are rearranged according to size, color, frequency, or another ordinal property.\n",
      "- SameDifferent - Objects are retained or manipulated based on whether they match or differ in some attribute (e.g., color, shape).\n",
      "- TopBottom2D - A flat 2D interpretation of objects where the top and bottom halves of the grid are compared or modified.\n",
      "- TopBottom3D - The task simulates a 3D stacking or layering behavior, such as viewing objects from above or combining vertical slices.\n",
      "\n",
      "Instructions:\n",
      "- Respond ONLY with the exact name of the matching concept from the list above.\n",
      "- Do not explain your answer, just return the concept.\n",
      "- If uncertain, choose the concept that fits best based on the input-output transformations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the tasks from the specified folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tasks(folder):\n",
    "    tasks = []\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        if filename.endswith(\".json\"):\n",
    "            with open(os.path.join(folder, filename), \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                tasks.append({\"filename\": filename, \"data\": data})\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads the API key from the .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_api_key(file_path=\"key.env\"):\n",
    "    load_dotenv(file_path)\n",
    "    import openai\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not openai.api_key:\n",
    "        print(\"No API key found. Please set OPENAI_API_KEY in key.env.\")\n",
    "    global client\n",
    "    client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used to send requests to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import openai\n",
    "\n",
    "def call_gpt(prompt, model=\"o4-mini\", retries=10):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                # Only for GPT-4o\n",
    "                # temperature=0.0\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        \n",
    "        except openai.RateLimitError as e:\n",
    "            wait_time = 5 + attempt * 5\n",
    "            print(f\"Rate limit hit. Waiting {wait_time} seconds before retrying...\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "    raise Exception(\"Rate limit retries exhausted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks if there already is a file documenting the assigned concepts for tasks. If yes, it loads it; if no, it creates an empty dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_file = \"classified_concepts.json\"\n",
    "if os.path.exists(concept_file):\n",
    "    with open(concept_file, \"r\") as f:\n",
    "        task_concepts = json.load(f)\n",
    "else:\n",
    "    task_concepts = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Concept Example to Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds the first task of the identified concept from the ConceptARC dataset to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_concept_examples(concept_name, base_path=\"ConceptARC_Data\"):\n",
    "    concept_path = os.path.join(base_path, concept_name, \"task.json\")\n",
    "    if not os.path.exists(concept_path):\n",
    "        print(f\"[Warning] No concept task found for '{concept_name}'\")\n",
    "        return \"\"\n",
    "    \n",
    "    with open(concept_path, \"r\") as f:\n",
    "        concept_task = json.load(f)\n",
    "    \n",
    "    formatted_examples = \"\\n\\nHere are a few examples following the same concept that may help with solving this task. Keep in mind that the identified concept may be faulty:\\n\"\n",
    "    for i, pair in enumerate(concept_task.get(\"train\", [])):\n",
    "        formatted_examples += f\"\\nConcept Train Input {i+1}: {pair['input']}\\n\"\n",
    "        formatted_examples += f\"Concept Train Output {i+1}: {pair['output']}\\n\"\n",
    "    \n",
    "    return formatted_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-zero Cords Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates encoded variants of the task data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_nonzero_coordinates(grid):\n",
    "    coords = []\n",
    "    for i, row in enumerate(grid):\n",
    "        for j, val in enumerate(row):\n",
    "            if val != 0:\n",
    "                coords.append({\"row\": i, \"col\": j, \"val\": val})\n",
    "    return coords\n",
    "\n",
    "def encode_task_nonzero_coords(task):\n",
    "    encoded = {\"train\": [], \"test\": []}\n",
    "\n",
    "    for pair in task[\"train\"]:\n",
    "        encoded[\"train\"].append({\n",
    "            \"input\": encode_nonzero_coordinates(pair[\"input\"]),\n",
    "            \"output\": encode_nonzero_coordinates(pair[\"output\"])\n",
    "        })\n",
    "\n",
    "    for pair in task[\"test\"]:\n",
    "        encoded[\"test\"].append({\n",
    "            \"input\": encode_nonzero_coordinates(pair[\"input\"])\n",
    "        })\n",
    "\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object/Bounding Box Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates encoded variants of the task data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def extract_objects(grid):\n",
    "    visited = set()\n",
    "    objects = []\n",
    "    rows, cols = len(grid), len(grid[0])\n",
    "\n",
    "    def bfs(r, c, color):\n",
    "        q = deque([(r, c)])\n",
    "        visited.add((r, c))\n",
    "        pixels = [(r, c)]\n",
    "        min_r, min_c = r, c\n",
    "        max_r, max_c = r, c\n",
    "\n",
    "        while q:\n",
    "            cr, cc = q.popleft()\n",
    "            for dr, dc in [(-1,0), (1,0), (0,-1), (0,1)]:\n",
    "                nr, nc = cr + dr, cc + dc\n",
    "                if (\n",
    "                    0 <= nr < rows and\n",
    "                    0 <= nc < cols and\n",
    "                    (nr, nc) not in visited and\n",
    "                    grid[nr][nc] == color\n",
    "                ):\n",
    "                    visited.add((nr, nc))\n",
    "                    q.append((nr, nc))\n",
    "                    pixels.append((nr, nc))\n",
    "                    min_r = min(min_r, nr)\n",
    "                    min_c = min(min_c, nc)\n",
    "                    max_r = max(max_r, nr)\n",
    "                    max_c = max(max_c, nc)\n",
    "\n",
    "        return {\n",
    "            \"color\": color,\n",
    "            \"top_left\": [min_r, min_c],\n",
    "            \"width\": max_c - min_c + 1,\n",
    "            \"height\": max_r - min_r + 1,\n",
    "            \"pixels\": pixels\n",
    "        }\n",
    "\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            color = grid[r][c]\n",
    "            if color != 0 and (r, c) not in visited:\n",
    "                objects.append(bfs(r, c, color))\n",
    "\n",
    "    return objects\n",
    "\n",
    "def encode_task_objects(task):\n",
    "    encoded = {\"train\": [], \"test\": []}\n",
    "\n",
    "    for pair in task[\"train\"]:\n",
    "        encoded[\"train\"].append({\n",
    "            \"input\": extract_objects(pair[\"input\"]),\n",
    "            \"output\": extract_objects(pair[\"output\"])\n",
    "        })\n",
    "\n",
    "    for pair in task[\"test\"]:\n",
    "        encoded[\"test\"].append({\n",
    "            \"input\": extract_objects(pair[\"input\"])\n",
    "        })\n",
    "\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Encoded Task to the Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds the encoded task data to the prompt, including a short description of the encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_encodings(prompt, encoding_dicts):\n",
    "    encoding_explanations = {\n",
    "        \"nonzero_coords\": \"This encoding lists only the non-zero cells as dictionaries containing their row, column, and value.\",\n",
    "        \"object_bbox\": \"This encoding represents each object in the grid as a group of connected same-colored cells, described by color, bounding box, and coordinates.\",\n",
    "    }\n",
    "\n",
    "    for encoding_name, encoding_data in encoding_dicts.items():\n",
    "        explanation = encoding_explanations.get(encoding_name, \"This encoding represents the input in an alternate form.\")\n",
    "        prompt += f\"\\n\\nEncoding used: {encoding_name}\\nExplanation: {explanation}\\n\\nHere are the demonstration pairs (encoded):\\n\"\n",
    "        for i, pair in enumerate(encoding_data[\"train\"]):\n",
    "            prompt += f\"\\nTrain Input {i+1}: {pair['input']}\\n\"\n",
    "            prompt += f\"Train Output {i+1}: {pair['output']}\\n\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Task-Tailored Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Tasks to the Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds the task data to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tasks(prompt, task_data):\n",
    "    full_prompt = prompt.strip() + \"\\n\\nHere are the demonstration pairs (JSON data):\\n\"\n",
    "    for i, pair in enumerate(task_data['train']):\n",
    "        full_prompt += f\"\\nTrain Input {i+1}: {pair['input']}\\n\"\n",
    "        full_prompt += f\"Train Output {i+1}: {pair['output']}\\n\"\n",
    "    return full_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Different Combination Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines secondary prompts 1 and 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prompts_1_and_2(prompt_1_response, prompt_2_template):\n",
    "    combined_prompt = f\"\"\"{prompt_2_template.strip()}\n",
    "\n",
    "Here are visual observations of the task at hand, that may assist you in identifying the transformation:\n",
    "\n",
    "{prompt_1_response.strip()}\n",
    "\n",
    "Now provide your transformation analysis based on these observations.\"\"\"\n",
    "    return combined_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines secondary prompts 1, 2, and 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prompts_1_2_and_3(prompt_1_response, prompt_2_response, prompt_3_template):\n",
    "    combined_prompt = f\"\"\"{prompt_3_template.strip()}\n",
    "\n",
    "Here are visual observations of the task that may help inform your implementation:\n",
    "{prompt_1_response.strip()}\n",
    "\n",
    "Here are the transformation rules that have been identified based on the task:\n",
    "{prompt_2_response.strip()}\n",
    "\n",
    "Now reflect on how you would implement a solution to this task in Python, following the instructions above.\n",
    "\"\"\"\n",
    "    return combined_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combines secondary prompts 1-3 with the base prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_prompts_and_base(prompt_1_response, prompt_2_response, prompt_3_response, prompt_base_template):\n",
    "    combined_prompt = f\"\"\"\n",
    "\n",
    "Here are visual observations of the task that may help inform your implementation:\n",
    "{prompt_1_response.strip()}\n",
    "\n",
    "Here are the transformation rules that have been identified based on the task:\n",
    "{prompt_2_response.strip()}\n",
    "    \n",
    "Here is a reflection on how you might implement a solution to this task in Python:\n",
    "{prompt_3_response.strip()}\n",
    "\n",
    "{prompt_base_template.strip()}\n",
    "\"\"\"\n",
    "    return combined_prompt.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of Task-Tailored Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates prompts 1-3 as well as the classification prompt and adds the LLMs responses to the task-tailored prompt (including encoding, task data, etc.). The result is a complete task-tailored prompt including:\n",
    "\n",
    "- Visual observations.\n",
    "- Transformation description.\n",
    "- Python implementation reflection.\n",
    "- Classification and examples of concept.\n",
    "- Additional encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_concepts = {}\n",
    "\n",
    "def build_prompts(task_data, task_id):\n",
    "    global task_concepts \n",
    "\n",
    "    # Create encodings\n",
    "    encoding_dicts = {\n",
    "        \"nonzero_coords\": encode_task_nonzero_coords(task_data),\n",
    "    }\n",
    "    \n",
    "    # Build prompt 1\n",
    "    full_prompt_1 = add_tasks(prompt_1, task_data)\n",
    "    full_prompt_1 = add_encodings(full_prompt_1, encoding_dicts)\n",
    "    response_1 = call_gpt(full_prompt_1)\n",
    "\n",
    "    # Build prompt 2\n",
    "    combined_prompt_2 = combine_prompts_1_and_2(response_1, prompt_2)\n",
    "    full_prompt_2 = add_tasks(combined_prompt_2, task_data)\n",
    "    full_prompt_2 = add_encodings(full_prompt_2, encoding_dicts)\n",
    "    response_2 = call_gpt(full_prompt_2)\n",
    "\n",
    "    # Build prompt 3\n",
    "    combined_prompt_3 = combine_prompts_1_2_and_3(response_1, response_2, prompt_3)\n",
    "    full_prompt_3 = add_tasks(combined_prompt_3, task_data)\n",
    "    full_prompt_3 = add_encodings(full_prompt_3, encoding_dicts)\n",
    "    response_3 = call_gpt(full_prompt_3)\n",
    "\n",
    "    # Classification step\n",
    "    if task_id in task_concepts:\n",
    "        predicted_concept = task_concepts[task_id]\n",
    "    else:\n",
    "        classification_full_prompt = add_tasks(classification_prompt, task_data)\n",
    "        classification_full_prompt = add_encodings(classification_full_prompt, encoding_dicts)\n",
    "        predicted_concept = call_gpt(classification_full_prompt).strip()\n",
    "\n",
    "        task_concepts[task_id] = predicted_concept\n",
    "        with open(concept_file, \"r\") as f:\n",
    "            all_concepts = json.load(f) if os.path.getsize(concept_file) > 0 else {}\n",
    "        all_concepts.update(task_concepts)\n",
    "        with open(concept_file, \"w\") as f:\n",
    "            json.dump(all_concepts, f, indent=2)\n",
    "        task_concepts = all_concepts\n",
    "\n",
    "    concept_instruction = load_concept_examples(predicted_concept)\n",
    "\n",
    "    # Build final tailored prompt\n",
    "    combined_prompt_base = combine_prompts_and_base(response_1, response_2, response_3, base_prompt)\n",
    "    tailored_prompt = add_tasks(combined_prompt_base, task_data)\n",
    "    tailored_prompt = add_encodings(tailored_prompt, encoding_dicts)\n",
    "    tailored_prompt += f\"\\n\\nThis task involves the concept: **{predicted_concept}**.\"\n",
    "    tailored_prompt += concept_instruction\n",
    "\n",
    "    print(\"Built tailored prompt.\")\n",
    "\n",
    "    return tailored_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function saves the generated programs in the specified folder using the task's name. Additionally, the LLMs response is cleaned, ensuring only runnable Python code is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_program(program_text, actual_task_id, suffix=\"\"):\n",
    "\n",
    "    base_folder = \"Candidate_programs_tailored_prompts_full\"\n",
    "    task_folder = os.path.join(base_folder, actual_task_id)\n",
    "    \n",
    "    os.makedirs(task_folder, exist_ok=True)\n",
    "\n",
    "    # Clean the LLMs response (e.g. remove ```python or ```)\n",
    "    cleaned_text = re.sub(r\"^```(?:python)?\\s*|```$\", \"\", program_text.strip(), flags=re.MULTILINE)\n",
    "\n",
    "    # Determine program version for naming\n",
    "    existing_files = os.listdir(task_folder)\n",
    "    version_numbers = [\n",
    "        int(re.search(r\"solution_v(\\d+)\", fname).group(1))\n",
    "        for fname in existing_files\n",
    "        if re.match(r\"solution_v\\d+\", fname)\n",
    "    ]\n",
    "    next_version = max(version_numbers, default=0) + 1\n",
    "    \n",
    "    # Save program to file\n",
    "    file_path = os.path.join(task_folder, f\"solution_v{next_version}{suffix}.py\")\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(cleaned_text.strip())\n",
    "\n",
    "    print(f\"Saved program for task {actual_task_id} as version {next_version}{suffix}: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function passes the prompt for program creation to the LLM for n amount of times and saves the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_programs(tailored_prompt, actual_task_id, amount):\n",
    "    for i in range(amount):\n",
    "        response = call_gpt(tailored_prompt)\n",
    "        save_program(response, actual_task_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads and executes a Python program from a specified file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_program(file_path):\n",
    "    spec = importlib.util.spec_from_file_location(\"program\", file_path)\n",
    "    program = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(program)\n",
    "    return program.solve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks if the program is valid Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_python_code(filepath):\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            source = f.read()\n",
    "        ast.parse(source)\n",
    "        return True\n",
    "    except SyntaxError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function runs the evaluation of the generated programs. This includes:\n",
    "\n",
    "- Checking if the program is valid Python code and deleting it if it isn't. \n",
    "- Checking if there are any valid programs among the generated ones (if there aren't at least two valid programs, more will be created until there are at least two [correctness of programs doesn't matter, only execution])\n",
    "- Comparing the generated outputs with the correct outputs.\n",
    "- Calculating a score for each program.\n",
    "\n",
    "The score is defined by the amount of correct transformations / the total amount of demonstration pairs of a task. This score is used to determine whether a program should be revised later on (score < 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_programs(task_data, task_folder):\n",
    "    programs = []\n",
    "    program_files = [f for f in os.listdir(task_folder) if f.endswith(\".py\")]\n",
    "\n",
    "    # Track whether any valid programs exist\n",
    "    any_valid = False\n",
    "\n",
    "    for program_file in program_files:\n",
    "        program_path = os.path.join(task_folder, program_file)\n",
    "\n",
    "        # Check if the program is valid Python code if not delete it\n",
    "        if not is_valid_python_code(program_path):\n",
    "            print(f\"Deleting invalid file: {program_file}\")\n",
    "            os.remove(program_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            solve_function = load_program(program_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading program {program_file}: {e}\")\n",
    "            os.remove(program_path)\n",
    "            continue\n",
    "\n",
    "        # Set to true if at least one valid program is found\n",
    "        any_valid = True\n",
    "\n",
    "        details = []\n",
    "        correct_count = 0\n",
    "        total_pairs = len(task_data['train'])\n",
    "\n",
    "        # Evaluate programs against the training pairs\n",
    "        for pair in task_data['train']:\n",
    "            input_grid = pair['input']\n",
    "            expected_output = pair['output']\n",
    "            try:\n",
    "                candidate_output = solve_function(input_grid)\n",
    "                if np.array_equal(np.array(candidate_output), np.array(expected_output)):\n",
    "                    correct_count += 1\n",
    "            except Exception as e:\n",
    "                candidate_output = f\"Error: {e}\"\n",
    "            details.append({\n",
    "                \"input\": input_grid,\n",
    "                \"candidate_output\": candidate_output,\n",
    "                \"expected_output\": expected_output\n",
    "            })\n",
    "\n",
    "        # Calculate the score and store the results\n",
    "        score = correct_count / total_pairs if total_pairs > 0 else 0\n",
    "        programs.append({\n",
    "            \"program_name\": program_file,\n",
    "            \"score\": score,\n",
    "            \"correct_pairs\": correct_count,\n",
    "            \"total_pairs\": total_pairs,\n",
    "            \"details\": details\n",
    "        })\n",
    "\n",
    "    return programs if any_valid else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of Revision Prompt and Revised Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function builds the revision prompt, including the following:\n",
    "\n",
    "- Generated Python code.\n",
    "- Task demonstration pairs.\n",
    "- Generated output.\n",
    "\n",
    "The prompt is used to task the LLM with creating a new program based on the revision. The program is then saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revise_candidate_program(candidate_file_path, task_data, actual_task_id):\n",
    "    # Load candidate code from the specified file path\n",
    "    with open(candidate_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        candidate_code_text = f.read()\n",
    "\n",
    "    try:\n",
    "        solve_fn = load_program(candidate_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading program for revision: {e}\")\n",
    "        return\n",
    "\n",
    "    ### Build the revision prompt ###\n",
    "    local_revision_prompt = revision_prompt + \"\\n\\nHere is the generated code:\\n\" + candidate_code_text + \"\\n\\nDemonstration Pairs:\\n\"\n",
    "\n",
    "    for i, pair in enumerate(task_data['train']):\n",
    "        try:\n",
    "            candidate_output = solve_fn(pair['input'])\n",
    "        except Exception as e:\n",
    "            candidate_output = f\"Error: {e}\"\n",
    "        local_revision_prompt += f\"{i+1}. Input: {pair['input']}\\n\"\n",
    "        local_revision_prompt += f\"   Expected Output: {pair['output']}\\n\"\n",
    "        local_revision_prompt += f\"   Generated Output: {candidate_output}\\n\"\n",
    "\n",
    "    local_revision_prompt += \"\\nPlease revise the code.\"\n",
    "\n",
    "\n",
    "    ### Call the LLM to revise the candidate code ###\n",
    "    revised_code = call_gpt(local_revision_prompt)\n",
    "\n",
    "\n",
    "    ### Determine revision level for naming and save the revised code ###\n",
    "    task_folder = os.path.join(\"Candidate_programs_tailored_prompts_full\", actual_task_id)\n",
    "    base_name = os.path.basename(candidate_file_path)\n",
    "    base_version_match = re.search(r\"solution_v(\\d+)\", base_name)\n",
    "    base_version = base_version_match.group(1) if base_version_match else \"1\"\n",
    "\n",
    "    existing_files = os.listdir(task_folder)\n",
    "    revision_count = len([\n",
    "        f for f in existing_files\n",
    "        if re.match(rf\"solution_v{base_version}_rev\\d+\\.py\", f)\n",
    "    ])\n",
    "    suffix = f\"_rev{revision_count + 1}\"\n",
    "\n",
    "    save_program(revised_code, actual_task_id, suffix=suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of Predictions on Test Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identification of Best Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selects the two best-performing programs based on their score (= performance on the demonstration pairs). If scores are equal over multiple programs, the first few programs will be picked (e.g., if all are 0, then solution_v1 and solution_v2 will be picked)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_programs(evaluation_results, actual_task_id, n=2):\n",
    "    # Sort programs by score descending; if scores are equal, the original order is preserved.\n",
    "    sorted_programs = sorted(evaluation_results, key=lambda x: x['score'], reverse=True)\n",
    "    task_folder = os.path.join(\"Candidate_programs_tailored_prompts_full\", actual_task_id)\n",
    "    best_program_files = [os.path.join(task_folder, prog['program_name']) for prog in sorted_programs[:n]]\n",
    "    for i in best_program_files:\n",
    "        print(f\"Best program: {i}\")\n",
    "    return best_program_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of Predictions on Test Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function loads the two best-performing programs to create predictions in the test inputs of the task. The resulting outputs are saved in a submission dictionary to be appended to the submission.json file later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_predictions(task_data, actual_task_id, best_program_files):\n",
    "    # Load candidate programs\n",
    "    best_solvers = [load_program(prog_file) for prog_file in best_program_files]\n",
    "    \n",
    "    predictions = []\n",
    "    # Iterate over each test pair and generate predictions\n",
    "    for i, pair in enumerate(task_data[\"test\"]):\n",
    "        input_grid = pair[\"input\"]\n",
    "        attempt_predictions = {}\n",
    "        for idx, solver in enumerate(best_solvers, start=1):\n",
    "            try:\n",
    "                output = solver(input_grid)\n",
    "            except Exception as e:\n",
    "                output = f\"Error: {e}\"\n",
    "            attempt_predictions[f\"attempt_{idx}\"] = output\n",
    "        predictions.append(attempt_predictions)\n",
    "    \n",
    "    # Save the predictions in the submission format\n",
    "    submission = {str(actual_task_id): predictions}\n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the flow of the pipeline. All the above functions and prompts are used and work together to create predictions for test inputs. The predictions are saved in a submission.json file for calculating the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built tailored prompt.\n",
      "Saved program for task 963f59bc as version 1: Candidate_programs_tailored_prompts_full\\963f59bc\\solution_v1.py\n",
      "Saved program for task 963f59bc as version 2: Candidate_programs_tailored_prompts_full\\963f59bc\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task 963f59bc as version 3_rev1: Candidate_programs_tailored_prompts_full\\963f59bc\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task 963f59bc as version 4_rev1: Candidate_programs_tailored_prompts_full\\963f59bc\\solution_v4_rev1.py\n",
      "Task 963f59bc evaluation results:\n",
      "Program solution_v1.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 1 out of 4 pairs. Score: 0.25\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\963f59bc\\solution_v4_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\963f59bc\\solution_v1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task 96a8c0cd as version 1: Candidate_programs_tailored_prompts_full\\96a8c0cd\\solution_v1.py\n",
      "Saved program for task 96a8c0cd as version 2: Candidate_programs_tailored_prompts_full\\96a8c0cd\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task 96a8c0cd as version 3_rev1: Candidate_programs_tailored_prompts_full\\96a8c0cd\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task 96a8c0cd as version 4_rev1: Candidate_programs_tailored_prompts_full\\96a8c0cd\\solution_v4_rev1.py\n",
      "Task 96a8c0cd evaluation results:\n",
      "Program solution_v1.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\96a8c0cd\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\96a8c0cd\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task 9b365c51 as version 1: Candidate_programs_tailored_prompts_full\\9b365c51\\solution_v1.py\n",
      "Saved program for task 9b365c51 as version 2: Candidate_programs_tailored_prompts_full\\9b365c51\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task 9b365c51 as version 3_rev1: Candidate_programs_tailored_prompts_full\\9b365c51\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task 9b365c51 as version 4_rev1: Candidate_programs_tailored_prompts_full\\9b365c51\\solution_v4_rev1.py\n",
      "Task 9b365c51 evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\9b365c51\\solution_v3_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\9b365c51\\solution_v1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task 9b4c17c4 as version 1: Candidate_programs_tailored_prompts_full\\9b4c17c4\\solution_v1.py\n",
      "Saved program for task 9b4c17c4 as version 2: Candidate_programs_tailored_prompts_full\\9b4c17c4\\solution_v2.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task 9b4c17c4 as version 3_rev1: Candidate_programs_tailored_prompts_full\\9b4c17c4\\solution_v3_rev1.py\n",
      "Task 9b4c17c4 evaluation results:\n",
      "Program solution_v1.py solved 4 out of 4 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\9b4c17c4\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\9b4c17c4\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task 9c1e755f as version 1: Candidate_programs_tailored_prompts_full\\9c1e755f\\solution_v1.py\n",
      "Saved program for task 9c1e755f as version 2: Candidate_programs_tailored_prompts_full\\9c1e755f\\solution_v2.py\n",
      "Task 9c1e755f evaluation results:\n",
      "Program solution_v1.py solved 4 out of 4 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 4 out of 4 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\9c1e755f\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\9c1e755f\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task a096bf4d as version 1: Candidate_programs_tailored_prompts_full\\a096bf4d\\solution_v1.py\n",
      "Saved program for task a096bf4d as version 2: Candidate_programs_tailored_prompts_full\\a096bf4d\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task a096bf4d as version 3_rev1: Candidate_programs_tailored_prompts_full\\a096bf4d\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task a096bf4d as version 4_rev1: Candidate_programs_tailored_prompts_full\\a096bf4d\\solution_v4_rev1.py\n",
      "Task a096bf4d evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\a096bf4d\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\a096bf4d\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task a59b95c0 as version 1: Candidate_programs_tailored_prompts_full\\a59b95c0\\solution_v1.py\n",
      "Saved program for task a59b95c0 as version 2: Candidate_programs_tailored_prompts_full\\a59b95c0\\solution_v2.py\n",
      "Task a59b95c0 evaluation results:\n",
      "Program solution_v1.py solved 5 out of 5 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 5 out of 5 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\a59b95c0\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\a59b95c0\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task a680ac02 as version 1: Candidate_programs_tailored_prompts_full\\a680ac02\\solution_v1.py\n",
      "Saved program for task a680ac02 as version 2: Candidate_programs_tailored_prompts_full\\a680ac02\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task a680ac02 as version 3_rev1: Candidate_programs_tailored_prompts_full\\a680ac02\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task a680ac02 as version 4_rev1: Candidate_programs_tailored_prompts_full\\a680ac02\\solution_v4_rev1.py\n",
      "Task a680ac02 evaluation results:\n",
      "Program solution_v1.py solved 1 out of 3 pairs. Score: 0.33\n",
      "==================================================\n",
      "Program solution_v2.py solved 1 out of 3 pairs. Score: 0.33\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\a680ac02\\solution_v3_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\a680ac02\\solution_v1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task a934301b as version 1: Candidate_programs_tailored_prompts_full\\a934301b\\solution_v1.py\n",
      "Saved program for task a934301b as version 2: Candidate_programs_tailored_prompts_full\\a934301b\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task a934301b as version 3_rev1: Candidate_programs_tailored_prompts_full\\a934301b\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task a934301b as version 4_rev1: Candidate_programs_tailored_prompts_full\\a934301b\\solution_v4_rev1.py\n",
      "Task a934301b evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 1 out of 3 pairs. Score: 0.33\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\a934301b\\solution_v3_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\a934301b\\solution_v4_rev1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task aa300dc3 as version 1: Candidate_programs_tailored_prompts_full\\aa300dc3\\solution_v1.py\n",
      "Saved program for task aa300dc3 as version 2: Candidate_programs_tailored_prompts_full\\aa300dc3\\solution_v2.py\n",
      "Task aa300dc3 evaluation results:\n",
      "Program solution_v1.py solved 4 out of 4 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 4 out of 4 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\aa300dc3\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\aa300dc3\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task aa4ec2a5 as version 1: Candidate_programs_tailored_prompts_full\\aa4ec2a5\\solution_v1.py\n",
      "Saved program for task aa4ec2a5 as version 2: Candidate_programs_tailored_prompts_full\\aa4ec2a5\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task aa4ec2a5 as version 3_rev1: Candidate_programs_tailored_prompts_full\\aa4ec2a5\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task aa4ec2a5 as version 4_rev1: Candidate_programs_tailored_prompts_full\\aa4ec2a5\\solution_v4_rev1.py\n",
      "Task aa4ec2a5 evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\aa4ec2a5\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\aa4ec2a5\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task aab50785 as version 1: Candidate_programs_tailored_prompts_full\\aab50785\\solution_v1.py\n",
      "Saved program for task aab50785 as version 2: Candidate_programs_tailored_prompts_full\\aab50785\\solution_v2.py\n",
      "Task aab50785 evaluation results:\n",
      "Program solution_v1.py solved 5 out of 5 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 5 out of 5 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\aab50785\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\aab50785\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task ac0c5833 as version 1: Candidate_programs_tailored_prompts_full\\ac0c5833\\solution_v1.py\n",
      "Saved program for task ac0c5833 as version 2: Candidate_programs_tailored_prompts_full\\ac0c5833\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task ac0c5833 as version 3_rev1: Candidate_programs_tailored_prompts_full\\ac0c5833\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task ac0c5833 as version 4_rev1: Candidate_programs_tailored_prompts_full\\ac0c5833\\solution_v4_rev1.py\n",
      "Task ac0c5833 evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\ac0c5833\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\ac0c5833\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task ac2e8ecf as version 1: Candidate_programs_tailored_prompts_full\\ac2e8ecf\\solution_v1.py\n",
      "Saved program for task ac2e8ecf as version 2: Candidate_programs_tailored_prompts_full\\ac2e8ecf\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task ac2e8ecf as version 3_rev1: Candidate_programs_tailored_prompts_full\\ac2e8ecf\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task ac2e8ecf as version 4_rev1: Candidate_programs_tailored_prompts_full\\ac2e8ecf\\solution_v4_rev1.py\n",
      "Task ac2e8ecf evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\ac2e8ecf\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\ac2e8ecf\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task ac605cbb as version 1: Candidate_programs_tailored_prompts_full\\ac605cbb\\solution_v1.py\n",
      "Saved program for task ac605cbb as version 2: Candidate_programs_tailored_prompts_full\\ac605cbb\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task ac605cbb as version 3_rev1: Candidate_programs_tailored_prompts_full\\ac605cbb\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task ac605cbb as version 4_rev1: Candidate_programs_tailored_prompts_full\\ac605cbb\\solution_v4_rev1.py\n",
      "Task ac605cbb evaluation results:\n",
      "Program solution_v1.py solved 0 out of 6 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 6 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 6 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 6 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\ac605cbb\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\ac605cbb\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task b9630600 as version 1: Candidate_programs_tailored_prompts_full\\b9630600\\solution_v1.py\n",
      "Saved program for task b9630600 as version 2: Candidate_programs_tailored_prompts_full\\b9630600\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task b9630600 as version 3_rev1: Candidate_programs_tailored_prompts_full\\b9630600\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task b9630600 as version 4_rev1: Candidate_programs_tailored_prompts_full\\b9630600\\solution_v4_rev1.py\n",
      "Task b9630600 evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\b9630600\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\b9630600\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task baf41dbf as version 1: Candidate_programs_tailored_prompts_full\\baf41dbf\\solution_v1.py\n",
      "Saved program for task baf41dbf as version 2: Candidate_programs_tailored_prompts_full\\baf41dbf\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task baf41dbf as version 3_rev1: Candidate_programs_tailored_prompts_full\\baf41dbf\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task baf41dbf as version 4_rev1: Candidate_programs_tailored_prompts_full\\baf41dbf\\solution_v4_rev1.py\n",
      "Task baf41dbf evaluation results:\n",
      "Program solution_v1.py solved 1 out of 3 pairs. Score: 0.33\n",
      "==================================================\n",
      "Program solution_v2.py solved 1 out of 3 pairs. Score: 0.33\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 2 out of 3 pairs. Score: 0.67\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 2 out of 3 pairs. Score: 0.67\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\baf41dbf\\solution_v3_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\baf41dbf\\solution_v4_rev1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task bb52a14b as version 1: Candidate_programs_tailored_prompts_full\\bb52a14b\\solution_v1.py\n",
      "Saved program for task bb52a14b as version 2: Candidate_programs_tailored_prompts_full\\bb52a14b\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task bb52a14b as version 3_rev1: Candidate_programs_tailored_prompts_full\\bb52a14b\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task bb52a14b as version 4_rev1: Candidate_programs_tailored_prompts_full\\bb52a14b\\solution_v4_rev1.py\n",
      "Task bb52a14b evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 1 out of 3 pairs. Score: 0.33\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\bb52a14b\\solution_v3_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\bb52a14b\\solution_v1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task bbb1b8b6 as version 1: Candidate_programs_tailored_prompts_full\\bbb1b8b6\\solution_v1.py\n",
      "Saved program for task bbb1b8b6 as version 2: Candidate_programs_tailored_prompts_full\\bbb1b8b6\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task bbb1b8b6 as version 3_rev1: Candidate_programs_tailored_prompts_full\\bbb1b8b6\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task bbb1b8b6 as version 4_rev1: Candidate_programs_tailored_prompts_full\\bbb1b8b6\\solution_v4_rev1.py\n",
      "Task bbb1b8b6 evaluation results:\n",
      "Program solution_v1.py solved 4 out of 7 pairs. Score: 0.57\n",
      "==================================================\n",
      "Program solution_v2.py solved 4 out of 7 pairs. Score: 0.57\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 7 out of 7 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 7 out of 7 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\bbb1b8b6\\solution_v3_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\bbb1b8b6\\solution_v4_rev1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task bcb3040b as version 1: Candidate_programs_tailored_prompts_full\\bcb3040b\\solution_v1.py\n",
      "Saved program for task bcb3040b as version 2: Candidate_programs_tailored_prompts_full\\bcb3040b\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task bcb3040b as version 3_rev1: Candidate_programs_tailored_prompts_full\\bcb3040b\\solution_v3_rev1.py\n",
      "Task bcb3040b evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\bcb3040b\\solution_v2.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\bcb3040b\\solution_v3_rev1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task bd14c3bf as version 1: Candidate_programs_tailored_prompts_full\\bd14c3bf\\solution_v1.py\n",
      "Saved program for task bd14c3bf as version 2: Candidate_programs_tailored_prompts_full\\bd14c3bf\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task bd14c3bf as version 3_rev1: Candidate_programs_tailored_prompts_full\\bd14c3bf\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task bd14c3bf as version 4_rev1: Candidate_programs_tailored_prompts_full\\bd14c3bf\\solution_v4_rev1.py\n",
      "Task bd14c3bf evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\bd14c3bf\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\bd14c3bf\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task c1990cce as version 1: Candidate_programs_tailored_prompts_full\\c1990cce\\solution_v1.py\n",
      "Saved program for task c1990cce as version 2: Candidate_programs_tailored_prompts_full\\c1990cce\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task c1990cce as version 3_rev1: Candidate_programs_tailored_prompts_full\\c1990cce\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task c1990cce as version 4_rev1: Candidate_programs_tailored_prompts_full\\c1990cce\\solution_v4_rev1.py\n",
      "Task c1990cce evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\c1990cce\\solution_v3_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\c1990cce\\solution_v4_rev1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task c64f1187 as version 1: Candidate_programs_tailored_prompts_full\\c64f1187\\solution_v1.py\n",
      "Saved program for task c64f1187 as version 2: Candidate_programs_tailored_prompts_full\\c64f1187\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task c64f1187 as version 3_rev1: Candidate_programs_tailored_prompts_full\\c64f1187\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task c64f1187 as version 4_rev1: Candidate_programs_tailored_prompts_full\\c64f1187\\solution_v4_rev1.py\n",
      "Task c64f1187 evaluation results:\n",
      "Program solution_v1.py solved 0 out of 2 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 2 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 1 out of 2 pairs. Score: 0.50\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 2 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\c64f1187\\solution_v3_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\c64f1187\\solution_v1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task c6e1b8da as version 1: Candidate_programs_tailored_prompts_full\\c6e1b8da\\solution_v1.py\n",
      "Saved program for task c6e1b8da as version 2: Candidate_programs_tailored_prompts_full\\c6e1b8da\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task c6e1b8da as version 3_rev1: Candidate_programs_tailored_prompts_full\\c6e1b8da\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task c6e1b8da as version 4_rev1: Candidate_programs_tailored_prompts_full\\c6e1b8da\\solution_v4_rev1.py\n",
      "Task c6e1b8da evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\c6e1b8da\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\c6e1b8da\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task ca8de6ea as version 1: Candidate_programs_tailored_prompts_full\\ca8de6ea\\solution_v1.py\n",
      "Saved program for task ca8de6ea as version 2: Candidate_programs_tailored_prompts_full\\ca8de6ea\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task ca8de6ea as version 3_rev1: Candidate_programs_tailored_prompts_full\\ca8de6ea\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task ca8de6ea as version 4_rev1: Candidate_programs_tailored_prompts_full\\ca8de6ea\\solution_v4_rev1.py\n",
      "Task ca8de6ea evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\ca8de6ea\\solution_v3_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\ca8de6ea\\solution_v4_rev1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task ca8f78db as version 1: Candidate_programs_tailored_prompts_full\\ca8f78db\\solution_v1.py\n",
      "Saved program for task ca8f78db as version 2: Candidate_programs_tailored_prompts_full\\ca8f78db\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task ca8f78db as version 3_rev1: Candidate_programs_tailored_prompts_full\\ca8f78db\\solution_v3_rev1.py\n",
      "Task ca8f78db evaluation results:\n",
      "Program solution_v1.py solved 2 out of 3 pairs. Score: 0.67\n",
      "==================================================\n",
      "Program solution_v2.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\ca8f78db\\solution_v2.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\ca8f78db\\solution_v3_rev1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task ce8d95cc as version 1: Candidate_programs_tailored_prompts_full\\ce8d95cc\\solution_v1.py\n",
      "Saved program for task ce8d95cc as version 2: Candidate_programs_tailored_prompts_full\\ce8d95cc\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task ce8d95cc as version 3_rev1: Candidate_programs_tailored_prompts_full\\ce8d95cc\\solution_v3_rev1.py\n",
      "Task ce8d95cc evaluation results:\n",
      "Program solution_v1.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 4 out of 4 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 4 out of 4 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\ce8d95cc\\solution_v2.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\ce8d95cc\\solution_v3_rev1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task cf133acc as version 1: Candidate_programs_tailored_prompts_full\\cf133acc\\solution_v1.py\n",
      "Saved program for task cf133acc as version 2: Candidate_programs_tailored_prompts_full\\cf133acc\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task cf133acc as version 3_rev1: Candidate_programs_tailored_prompts_full\\cf133acc\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task cf133acc as version 4_rev1: Candidate_programs_tailored_prompts_full\\cf133acc\\solution_v4_rev1.py\n",
      "Task cf133acc evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\cf133acc\\solution_v4_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\cf133acc\\solution_v1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task cfb2ce5a as version 1: Candidate_programs_tailored_prompts_full\\cfb2ce5a\\solution_v1.py\n",
      "Saved program for task cfb2ce5a as version 2: Candidate_programs_tailored_prompts_full\\cfb2ce5a\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task cfb2ce5a as version 3_rev1: Candidate_programs_tailored_prompts_full\\cfb2ce5a\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task cfb2ce5a as version 4_rev1: Candidate_programs_tailored_prompts_full\\cfb2ce5a\\solution_v4_rev1.py\n",
      "Task cfb2ce5a evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\cfb2ce5a\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\cfb2ce5a\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task d282b262 as version 1: Candidate_programs_tailored_prompts_full\\d282b262\\solution_v1.py\n",
      "Saved program for task d282b262 as version 2: Candidate_programs_tailored_prompts_full\\d282b262\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task d282b262 as version 3_rev1: Candidate_programs_tailored_prompts_full\\d282b262\\solution_v3_rev1.py\n",
      "Task d282b262 evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\d282b262\\solution_v2.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\d282b262\\solution_v3_rev1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task d2acf2cb as version 1: Candidate_programs_tailored_prompts_full\\d2acf2cb\\solution_v1.py\n",
      "Saved program for task d2acf2cb as version 2: Candidate_programs_tailored_prompts_full\\d2acf2cb\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task d2acf2cb as version 3_rev1: Candidate_programs_tailored_prompts_full\\d2acf2cb\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task d2acf2cb as version 4_rev1: Candidate_programs_tailored_prompts_full\\d2acf2cb\\solution_v4_rev1.py\n",
      "Task d2acf2cb evaluation results:\n",
      "Program solution_v1.py solved 1 out of 3 pairs. Score: 0.33\n",
      "==================================================\n",
      "Program solution_v2.py solved 1 out of 3 pairs. Score: 0.33\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 2 out of 3 pairs. Score: 0.67\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\d2acf2cb\\solution_v4_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\d2acf2cb\\solution_v3_rev1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task d56f2372 as version 1: Candidate_programs_tailored_prompts_full\\d56f2372\\solution_v1.py\n",
      "Saved program for task d56f2372 as version 2: Candidate_programs_tailored_prompts_full\\d56f2372\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task d56f2372 as version 3_rev1: Candidate_programs_tailored_prompts_full\\d56f2372\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task d56f2372 as version 4_rev1: Candidate_programs_tailored_prompts_full\\d56f2372\\solution_v4_rev1.py\n",
      "Task d56f2372 evaluation results:\n",
      "Program solution_v1.py solved 1 out of 3 pairs. Score: 0.33\n",
      "==================================================\n",
      "Program solution_v2.py solved 1 out of 3 pairs. Score: 0.33\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 1 out of 3 pairs. Score: 0.33\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 1 out of 3 pairs. Score: 0.33\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\d56f2372\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\d56f2372\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task da2b0fe3 as version 1: Candidate_programs_tailored_prompts_full\\da2b0fe3\\solution_v1.py\n",
      "Saved program for task da2b0fe3 as version 2: Candidate_programs_tailored_prompts_full\\da2b0fe3\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task da2b0fe3 as version 3_rev1: Candidate_programs_tailored_prompts_full\\da2b0fe3\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task da2b0fe3 as version 4_rev1: Candidate_programs_tailored_prompts_full\\da2b0fe3\\solution_v4_rev1.py\n",
      "Task da2b0fe3 evaluation results:\n",
      "Program solution_v1.py solved 1 out of 3 pairs. Score: 0.33\n",
      "==================================================\n",
      "Program solution_v2.py solved 1 out of 3 pairs. Score: 0.33\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 2 out of 3 pairs. Score: 0.67\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\da2b0fe3\\solution_v4_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\da2b0fe3\\solution_v3_rev1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task dc2e9a9d as version 1: Candidate_programs_tailored_prompts_full\\dc2e9a9d\\solution_v1.py\n",
      "Saved program for task dc2e9a9d as version 2: Candidate_programs_tailored_prompts_full\\dc2e9a9d\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task dc2e9a9d as version 3_rev1: Candidate_programs_tailored_prompts_full\\dc2e9a9d\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task dc2e9a9d as version 4_rev1: Candidate_programs_tailored_prompts_full\\dc2e9a9d\\solution_v4_rev1.py\n",
      "Task dc2e9a9d evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\dc2e9a9d\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\dc2e9a9d\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task de493100 as version 1: Candidate_programs_tailored_prompts_full\\de493100\\solution_v1.py\n",
      "Saved program for task de493100 as version 2: Candidate_programs_tailored_prompts_full\\de493100\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task de493100 as version 3_rev1: Candidate_programs_tailored_prompts_full\\de493100\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task de493100 as version 4_rev1: Candidate_programs_tailored_prompts_full\\de493100\\solution_v4_rev1.py\n",
      "Task de493100 evaluation results:\n",
      "Program solution_v1.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\de493100\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\de493100\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task e0fb7511 as version 1: Candidate_programs_tailored_prompts_full\\e0fb7511\\solution_v1.py\n",
      "Saved program for task e0fb7511 as version 2: Candidate_programs_tailored_prompts_full\\e0fb7511\\solution_v2.py\n",
      "Task e0fb7511 evaluation results:\n",
      "Program solution_v1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\e0fb7511\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\e0fb7511\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task e66aafb8 as version 1: Candidate_programs_tailored_prompts_full\\e66aafb8\\solution_v1.py\n",
      "Saved program for task e66aafb8 as version 2: Candidate_programs_tailored_prompts_full\\e66aafb8\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task e66aafb8 as version 3_rev1: Candidate_programs_tailored_prompts_full\\e66aafb8\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task e66aafb8 as version 4_rev1: Candidate_programs_tailored_prompts_full\\e66aafb8\\solution_v4_rev1.py\n",
      "Task e66aafb8 evaluation results:\n",
      "Program solution_v1.py solved 0 out of 5 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 5 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 5 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 5 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\e66aafb8\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\e66aafb8\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task e6de6e8f as version 1: Candidate_programs_tailored_prompts_full\\e6de6e8f\\solution_v1.py\n",
      "Saved program for task e6de6e8f as version 2: Candidate_programs_tailored_prompts_full\\e6de6e8f\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task e6de6e8f as version 3_rev1: Candidate_programs_tailored_prompts_full\\e6de6e8f\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task e6de6e8f as version 4_rev1: Candidate_programs_tailored_prompts_full\\e6de6e8f\\solution_v4_rev1.py\n",
      "Task e6de6e8f evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\e6de6e8f\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\e6de6e8f\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task e74e1818 as version 1: Candidate_programs_tailored_prompts_full\\e74e1818\\solution_v1.py\n",
      "Saved program for task e74e1818 as version 2: Candidate_programs_tailored_prompts_full\\e74e1818\\solution_v2.py\n",
      "Task e74e1818 evaluation results:\n",
      "Program solution_v1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\e74e1818\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\e74e1818\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task e872b94a as version 1: Candidate_programs_tailored_prompts_full\\e872b94a\\solution_v1.py\n",
      "Saved program for task e872b94a as version 2: Candidate_programs_tailored_prompts_full\\e872b94a\\solution_v2.py\n",
      "[[0], [0], [0]]\n",
      "[[0]]\n",
      "[[0], [0]]\n",
      "[[0], [0], [0], [0]]\n",
      "Revising solution_v1.py...\n",
      "[[0], [0], [0]]\n",
      "[[0]]\n",
      "[[0], [0]]\n",
      "[[0], [0], [0], [0]]\n",
      "Saved program for task e872b94a as version 3_rev1: Candidate_programs_tailored_prompts_full\\e872b94a\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task e872b94a as version 4_rev1: Candidate_programs_tailored_prompts_full\\e872b94a\\solution_v4_rev1.py\n",
      "[[0], [0], [0]]\n",
      "[[0]]\n",
      "[[0], [0]]\n",
      "[[0], [0], [0], [0]]\n",
      "Task e872b94a evaluation results:\n",
      "Program solution_v1.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 4 out of 4 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\e872b94a\\solution_v3_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\e872b94a\\solution_v1.py\n",
      "[[0], [0], [0]]\n",
      "[[0]]\n",
      "[[0], [0]]\n",
      "[[0], [0], [0], [0]]\n",
      "Built tailored prompt.\n",
      "Saved program for task e9b4f6fc as version 1: Candidate_programs_tailored_prompts_full\\e9b4f6fc\\solution_v1.py\n",
      "Saved program for task e9b4f6fc as version 2: Candidate_programs_tailored_prompts_full\\e9b4f6fc\\solution_v2.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task e9b4f6fc as version 3_rev1: Candidate_programs_tailored_prompts_full\\e9b4f6fc\\solution_v3_rev1.py\n",
      "Task e9b4f6fc evaluation results:\n",
      "Program solution_v1.py solved 4 out of 4 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 4 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 4 out of 4 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\e9b4f6fc\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\e9b4f6fc\\solution_v3_rev1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task e9c9d9a1 as version 1: Candidate_programs_tailored_prompts_full\\e9c9d9a1\\solution_v1.py\n",
      "Saved program for task e9c9d9a1 as version 2: Candidate_programs_tailored_prompts_full\\e9c9d9a1\\solution_v2.py\n",
      "Task e9c9d9a1 evaluation results:\n",
      "Program solution_v1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\e9c9d9a1\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\e9c9d9a1\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task ed98d772 as version 1: Candidate_programs_tailored_prompts_full\\ed98d772\\solution_v1.py\n",
      "Saved program for task ed98d772 as version 2: Candidate_programs_tailored_prompts_full\\ed98d772\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task ed98d772 as version 3_rev1: Candidate_programs_tailored_prompts_full\\ed98d772\\solution_v3_rev1.py\n",
      "Task ed98d772 evaluation results:\n",
      "Program solution_v1.py solved 0 out of 5 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 5 out of 5 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 5 out of 5 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\ed98d772\\solution_v2.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\ed98d772\\solution_v3_rev1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task f0df5ff0 as version 1: Candidate_programs_tailored_prompts_full\\f0df5ff0\\solution_v1.py\n",
      "Saved program for task f0df5ff0 as version 2: Candidate_programs_tailored_prompts_full\\f0df5ff0\\solution_v2.py\n",
      "Error loading program solution_v2.py: name 'List' is not defined\n",
      "Task f0df5ff0 evaluation results:\n",
      "Program solution_v1.py solved 3 out of 3 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\f0df5ff0\\solution_v1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task f4081712 as version 1: Candidate_programs_tailored_prompts_full\\f4081712\\solution_v1.py\n",
      "Saved program for task f4081712 as version 2: Candidate_programs_tailored_prompts_full\\f4081712\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task f4081712 as version 3_rev1: Candidate_programs_tailored_prompts_full\\f4081712\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task f4081712 as version 4_rev1: Candidate_programs_tailored_prompts_full\\f4081712\\solution_v4_rev1.py\n",
      "Task f4081712 evaluation results:\n",
      "Program solution_v1.py solved 0 out of 5 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 5 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 5 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 5 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\f4081712\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\f4081712\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task fafd9572 as version 1: Candidate_programs_tailored_prompts_full\\fafd9572\\solution_v1.py\n",
      "Saved program for task fafd9572 as version 2: Candidate_programs_tailored_prompts_full\\fafd9572\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task fafd9572 as version 3_rev1: Candidate_programs_tailored_prompts_full\\fafd9572\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task fafd9572 as version 4_rev1: Candidate_programs_tailored_prompts_full\\fafd9572\\solution_v4_rev1.py\n",
      "Task fafd9572 evaluation results:\n",
      "Program solution_v1.py solved 0 out of 2 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 2 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 1 out of 2 pairs. Score: 0.50\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 2 out of 2 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\fafd9572\\solution_v4_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\fafd9572\\solution_v3_rev1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task fd096ab6 as version 1: Candidate_programs_tailored_prompts_full\\fd096ab6\\solution_v1.py\n",
      "Saved program for task fd096ab6 as version 2: Candidate_programs_tailored_prompts_full\\fd096ab6\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task fd096ab6 as version 3_rev1: Candidate_programs_tailored_prompts_full\\fd096ab6\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task fd096ab6 as version 4_rev1: Candidate_programs_tailored_prompts_full\\fd096ab6\\solution_v4_rev1.py\n",
      "Task fd096ab6 evaluation results:\n",
      "Program solution_v1.py solved 0 out of 2 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 2 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 2 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 2 out of 2 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\fd096ab6\\solution_v4_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\fd096ab6\\solution_v1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task fd4b2b02 as version 1: Candidate_programs_tailored_prompts_full\\fd4b2b02\\solution_v1.py\n",
      "Saved program for task fd4b2b02 as version 2: Candidate_programs_tailored_prompts_full\\fd4b2b02\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task fd4b2b02 as version 3_rev1: Candidate_programs_tailored_prompts_full\\fd4b2b02\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task fd4b2b02 as version 4_rev1: Candidate_programs_tailored_prompts_full\\fd4b2b02\\solution_v4_rev1.py\n",
      "Task fd4b2b02 evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\fd4b2b02\\solution_v1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\fd4b2b02\\solution_v2.py\n",
      "Built tailored prompt.\n",
      "Saved program for task fe9372f3 as version 1: Candidate_programs_tailored_prompts_full\\fe9372f3\\solution_v1.py\n",
      "Saved program for task fe9372f3 as version 2: Candidate_programs_tailored_prompts_full\\fe9372f3\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task fe9372f3 as version 3_rev1: Candidate_programs_tailored_prompts_full\\fe9372f3\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task fe9372f3 as version 4_rev1: Candidate_programs_tailored_prompts_full\\fe9372f3\\solution_v4_rev1.py\n",
      "Task fe9372f3 evaluation results:\n",
      "Program solution_v1.py solved 0 out of 2 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 2 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 2 out of 2 pairs. Score: 1.00\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 2 out of 2 pairs. Score: 1.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\fe9372f3\\solution_v3_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\fe9372f3\\solution_v4_rev1.py\n",
      "Built tailored prompt.\n",
      "Saved program for task fea12743 as version 1: Candidate_programs_tailored_prompts_full\\fea12743\\solution_v1.py\n",
      "Saved program for task fea12743 as version 2: Candidate_programs_tailored_prompts_full\\fea12743\\solution_v2.py\n",
      "Revising solution_v1.py...\n",
      "Saved program for task fea12743 as version 3_rev1: Candidate_programs_tailored_prompts_full\\fea12743\\solution_v3_rev1.py\n",
      "Revising solution_v2.py...\n",
      "Saved program for task fea12743 as version 4_rev1: Candidate_programs_tailored_prompts_full\\fea12743\\solution_v4_rev1.py\n",
      "Task fea12743 evaluation results:\n",
      "Program solution_v1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v2.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Program solution_v3_rev1.py solved 1 out of 3 pairs. Score: 0.33\n",
      "==================================================\n",
      "Program solution_v4_rev1.py solved 0 out of 3 pairs. Score: 0.00\n",
      "==================================================\n",
      "Best program: Candidate_programs_tailored_prompts_full\\fea12743\\solution_v3_rev1.py\n",
      "Best program: Candidate_programs_tailored_prompts_full\\fea12743\\solution_v1.py\n"
     ]
    }
   ],
   "source": [
    "# Load tasks and API key\n",
    "tasks = load_tasks(\"evaluation_set\")\n",
    "load_api_key()\n",
    "\n",
    "# Load existing submission file if it exists\n",
    "submission_file = \"submission_tailored_prompts_full.json\"\n",
    "if os.path.exists(submission_file):\n",
    "    with open(submission_file, \"r\") as f:\n",
    "        final_submission = json.load(f)\n",
    "else:\n",
    "    final_submission = {}\n",
    "\n",
    "# Loop through each task (adjustable range)\n",
    "for i, task in enumerate(tasks[:100]):\n",
    "    actual_task_id = task[\"filename\"].split(\".\")[0]\n",
    "    \n",
    "    ### PROMPT CREATION ###\n",
    "    tailored_prompt = build_prompts(task['data'], actual_task_id)\n",
    "    create_programs(tailored_prompt, actual_task_id, amount=2)\n",
    "    \n",
    "    ### INITIAL EVALUATION ###\n",
    "    task_folder = os.path.join(\"Candidate_programs_tailored_prompts_full\", actual_task_id)\n",
    "    evaluation_results = evaluate_programs(task['data'], task_folder)\n",
    "    \n",
    "    while evaluation_results == 0:\n",
    "        create_programs(tailored_prompt, actual_task_id, amount=2)\n",
    "        evaluation_results = evaluate_programs(task['data'], task_folder)\n",
    "\n",
    "    ### FIRST REVISION: Revise all < 1 ###\n",
    "    for result in evaluation_results:\n",
    "        if result['score'] < 1:\n",
    "            candidate_file = os.path.join(task_folder, result['program_name'])\n",
    "            print(f\"Revising {result['program_name']}...\")\n",
    "            revise_candidate_program(candidate_file, task['data'], actual_task_id)\n",
    "\n",
    "    ### FINAL EVALUATION ###\n",
    "    evaluation_results_2 = evaluate_programs(task['data'], task_folder)\n",
    "    print(f\"Task {actual_task_id} evaluation results:\")\n",
    "    for result in evaluation_results_2:\n",
    "        print(f\"Program {result['program_name']} solved {result['correct_pairs']} out of {result['total_pairs']} pairs. Score: {result['score']:.2f}\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "    ### PROGRAM SELECTION + PREDICTIONS ###\n",
    "    best_program_files = get_best_programs(evaluation_results_2, actual_task_id, n=2)\n",
    "    submission = generate_test_predictions(task['data'], actual_task_id, best_program_files)\n",
    "    final_submission.update(submission)\n",
    "\n",
    "# Final output file\n",
    "with open(submission_file, \"w\") as f:\n",
    "    json.dump(final_submission, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
