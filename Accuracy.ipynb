{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93becf07",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3a256a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718da050",
   "metadata": {},
   "source": [
    "### Functions for Calculation and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43914255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tasks(folder):\n",
    "    tasks = []\n",
    "    for filename in sorted(os.listdir(folder)):\n",
    "        if filename.endswith(\".json\"):\n",
    "            with open(os.path.join(folder, filename), \"r\") as f:\n",
    "                data = json.load(f)\n",
    "                tasks.append({\"filename\": filename, \"data\": data})\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dfb852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_equal(a, b):\n",
    "    return json.dumps(a) == json.dumps(b)\n",
    "\n",
    "def compute_accuracy(submission_path, tasks_dict, task_concepts):\n",
    "    with open(submission_path, 'r') as f:\n",
    "        submission = json.load(f)\n",
    "\n",
    "    total_tasks = len(submission)\n",
    "    correct_tasks = 0\n",
    "\n",
    "    concept_totals = {}\n",
    "    concept_corrects = {}\n",
    "\n",
    "    for task_id, prediction_list in submission.items():\n",
    "        task_data = tasks_dict[task_id]\n",
    "        test_outputs = [test['output'] for test in task_data['test']]\n",
    "\n",
    "        all_test_cases_correct = True\n",
    "        for idx, expected_output in enumerate(test_outputs):\n",
    "            attempts = prediction_list[idx]\n",
    "            pred1 = attempts.get(\"attempt_1\")\n",
    "            pred2 = attempts.get(\"attempt_2\")  # may be None\n",
    "\n",
    "            if not (are_equal(pred1, expected_output) or (pred2 is not None and are_equal(pred2, expected_output))):\n",
    "                all_test_cases_correct = False\n",
    "                break\n",
    "\n",
    "        concept = task_concepts.get(task_id, \"Unknown Concept\")\n",
    "        concept_totals[concept] = concept_totals.get(concept, 0) + 1\n",
    "        if all_test_cases_correct:\n",
    "            correct_tasks += 1\n",
    "            concept_corrects[concept] = concept_corrects.get(concept, 0) + 1\n",
    "\n",
    "    accuracy = correct_tasks / total_tasks\n",
    "\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.2%}\\n\")\n",
    "\n",
    "    print(\"Accuracy per concept:\")\n",
    "    for concept, total in concept_totals.items():\n",
    "        correct = concept_corrects.get(concept, 0)\n",
    "        concept_accuracy = correct / total\n",
    "        print(f\"- {concept}: {correct}/{total} ({concept_accuracy:.2%})\")\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a079ab",
   "metadata": {},
   "source": [
    "### Accuracy and Algorithm Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343ab37b",
   "metadata": {},
   "source": [
    "If you want to get the accuracy of a different pipeline/task group, change the following variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d17e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_selection = \"evaluation_set\"\n",
    "pipeline_submission = \"submission_revision-loop_4o.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a353383b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Accuracy: 5.00%\n",
      "\n",
      "Accuracy per concept:\n",
      "- CleanUp: 0/2 (0.00%)\n",
      "- ExtractObjects: 0/18 (0.00%)\n",
      "- FilledNotFilled: 0/10 (0.00%)\n",
      "- ExtendToBoundary: 0/13 (0.00%)\n",
      "- HorizontalVertical: 1/6 (16.67%)\n",
      "- Copy: 1/19 (5.26%)\n",
      "- SameDifferent: 0/3 (0.00%)\n",
      "- Order: 0/6 (0.00%)\n",
      "- Count: 3/5 (60.00%)\n",
      "- CompleteShape: 0/10 (0.00%)\n",
      "- AboveBelow: 0/2 (0.00%)\n",
      "- InsideOutside: 0/3 (0.00%)\n",
      "- MoveToBoundary: 0/3 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "tasks = load_tasks(task_selection)\n",
    "with open(\"classified_concepts.json\") as f:\n",
    "    task_concepts = json.load(f)\n",
    "\n",
    "with open(pipeline_submission) as f:\n",
    "    submission = json.load(f)\n",
    "\n",
    "tasks_dict = {task[\"filename\"].split(\".\")[0]: task[\"data\"] for task in tasks}\n",
    "\n",
    "accuracy = compute_accuracy(pipeline_submission, tasks_dict, task_concepts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
